|    value_loss           | 0.0639   |
| stat/                   |          |
|    constraint_violation | 48       |
|    ep_constraint_vio... | 4.1      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.914    |
| stat_eval/              |          |
|    constraint_violation | 8.4      |
|    ep_length            | 150      |
|    ep_return            | 133      |
|    ep_reward            | 0.886    |
|    mse                  | 133      |
| time/                   |          |
|    progress             | 0.5      |
|    step                 | 3e+03    |
|    step_time            | 0.629    |
--------------------------------------

2023-09-05 11:41:52,182 : Checkpoint | temp/model_latest.pt
2023-09-05 11:41:53,273 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 134.049 +/- 5.782
eval_results['h_violation']:[16  8 16 24 20  8 10 12 12 16], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:124.96718987179815
2023-09-05 11:41:53,277 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.638    |
|    lambda training step | 6        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0354   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0523   |
|    entropy_loss         | 1.93     |
|    policy_loss          | 0.0158   |
|    value_loss           | 0.139    |
| stat/                   |          |
|    constraint_violation | 170      |
|    ep_constraint_vio... | 7.3      |
|    ep_length            | 150      |
|    ep_return            | 134      |
|    ep_reward            | 0.896    |
| stat_eval/              |          |
|    constraint_violation | 9.4      |
|    ep_length            | 150      |
|    ep_return            | 134      |
|    ep_reward            | 0.894    |
|    mse                  | 142      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 6e+03    |
|    step_time            | 0.707    |
--------------------------------------

Training done.
training step :5, total: 5.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
Starting evaluation of constraints
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 124.468
←[33maverage_rmse←[0m: 1.176
←[33mrmse←[0m: 1.176
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 1.176
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 57.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 57.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 126.074
←[33maverage_rmse←[0m: 0.996
←[33mrmse←[0m: 0.996
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.996
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 18.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 18.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 131.232
←[33maverage_rmse←[0m: 0.793
←[33mrmse←[0m: 0.793
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.793
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 10.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 10.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 140.846
←[33maverage_rmse←[0m: 1.067
←[33mrmse←[0m: 1.067
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 1.067
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 29.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 29.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 130.372
←[33maverage_rmse←[0m: 0.896
←[33mrmse←[0m: 0.896
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.896
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 16.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 16.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 126.913
←[33maverage_rmse←[0m: 1.565
←[33mrmse←[0m: 1.565
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 1.565
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 110.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 110.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 146.133
←[33maverage_rmse←[0m: 0.551
←[33mrmse←[0m: 0.551
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.551
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 144.740
←[33maverage_rmse←[0m: 0.672
←[33mrmse←[0m: 0.672
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.672
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 132.556
←[33maverage_rmse←[0m: 0.639
←[33mrmse←[0m: 0.639
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.639
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 139.820
←[33maverage_rmse←[0m: 0.874
←[33mrmse←[0m: 0.874
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.874
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 134.519
←[33maverage_rmse←[0m: 0.747
←[33mrmse←[0m: 0.747
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.747
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 4.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 4.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 145.060
←[33maverage_rmse←[0m: 0.650
←[33mrmse←[0m: 0.650
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.650
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 142.772
←[33maverage_rmse←[0m: 0.771
←[33mrmse←[0m: 0.771
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.771
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 139.394
←[33maverage_rmse←[0m: 0.887
←[33mrmse←[0m: 0.887
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.887
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 133.747
←[33maverage_rmse←[0m: 1.024
←[33mrmse←[0m: 1.024
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 1.024
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 27.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 27.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 145.687
←[33maverage_rmse←[0m: 0.599
←[33mrmse←[0m: 0.599
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.599
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 126.055
←[33maverage_rmse←[0m: 1.308
←[33mrmse←[0m: 1.308
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 1.308
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 72.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 72.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 117.566
←[33maverage_rmse←[0m: 0.905
←[33mrmse←[0m: 0.905
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.905
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 12.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 12.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 144.855
←[33maverage_rmse←[0m: 0.664
←[33mrmse←[0m: 0.664
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.664
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 116.169
←[33maverage_rmse←[0m: 0.671
←[33mrmse←[0m: 0.671
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.671
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 9.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 9.000
Evaluation done.
Updating Lambdas: lamb_1_gradient=17.05, lamb_2_gradient=0.7
Policy update: 5th step, Lambda update: 6th step
current lambdas: (0.6376000000000001, 0.03541413651653513)
2023-09-05 11:42:00,370 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:01,430 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.311 +/- 3.373
eval_results['h_violation']:[ 0  0 11 10  0  8  0  0 11  0], (eval_results['s_violation']>0):[[ True]
 [False]
 [False]
 [ True]
 [False]
 [ True]
 [False]
 [False]
 [ True]
 [False]], eval_score:135.60941265025687
2023-09-05 11:42:01,434 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.672    |
|    lambda training step | 7        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0367   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0264   |
|    entropy_loss         | 1.93     |
|    policy_loss          | 0.00201  |
|    value_loss           | 0.229    |
| stat/                   |          |
|    constraint_violation | 127      |
|    ep_constraint_vio... | 7.8      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.91     |
| stat_eval/              |          |
|    constraint_violation | 5.9      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.922    |
|    mse                  | 122      |
| time/                   |          |
|    progress             | 0.5      |
|    step                 | 3e+03    |
|    step_time            | 0.626    |
--------------------------------------

2023-09-05 11:42:04,588 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:05,645 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.788 +/- 4.872
eval_results['h_violation']:[ 0 10  7 13 19  1  0 14  7  5], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [False]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [False]], eval_score:132.66520741896036
2023-09-05 11:42:05,649 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.672    |
|    lambda training step | 7        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0367   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0218   |
|    entropy_loss         | 1.94     |
|    policy_loss          | 0.00355  |
|    value_loss           | 0.107    |
| stat/                   |          |
|    constraint_violation | 282      |
|    ep_constraint_vio... | 4.8      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.915    |
| stat_eval/              |          |
|    constraint_violation | 5.2      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.919    |
|    mse                  | 122      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 6e+03    |
|    step_time            | 0.627    |
--------------------------------------

Training done.
training step :1, total: 5.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:42:08,793 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:09,850 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.730 +/- 4.833
eval_results['h_violation']:[ 0  1 11 17  4  0  0  8  0 16], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [False]
 [ True]
 [False]
 [False]
 [False]
 [ True]
 [False]], eval_score:132.88652679007973
2023-09-05 11:42:09,855 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.672    |
|    lambda training step | 7        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0367   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0347   |
|    entropy_loss         | 1.94     |
|    policy_loss          | -0.0003  |
|    value_loss           | 0.223    |
| stat/                   |          |
|    constraint_violation | 152      |
|    ep_constraint_vio... | 5        |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.918    |
| stat_eval/              |          |
|    constraint_violation | 5.4      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.912    |
|    mse                  | 119      |
| time/                   |          |
|    progress             | 0.5      |
|    step                 | 3e+03    |
|    step_time            | 0.602    |
--------------------------------------

2023-09-05 11:42:12,999 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:14,062 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.583 +/- 4.243
eval_results['h_violation']:[ 0  0  0 10  0  0 22 11  0  0], (eval_results['s_violation']>0):[[False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [ True]], eval_score:134.67234408673485
2023-09-05 11:42:14,066 :
---------------------------------------
| lambda/                 |           |
|    current env steps    | 6e+03     |
|    current updating ... | 1         |
|    hard_lambda          | 0.672     |
|    lambda training step | 7         |
|    policy update step   | 5         |
|    soft_lambda          | 0.0367    |
|    trajectory scale     | 0         |
| loss/                   |           |
|    approx_kl            | 0.0166    |
|    entropy_loss         | 1.95      |
|    policy_loss          | -0.000566 |
|    value_loss           | 0.009     |
| stat/                   |           |
|    constraint_violation | 265       |
|    ep_constraint_vio... | 6.7       |
|    ep_length            | 150       |
|    ep_return            | 135       |
|    ep_reward            | 0.898     |
| stat_eval/              |           |
|    constraint_violation | 4.4       |
|    ep_length            | 150       |
|    ep_return            | 138       |
|    ep_reward            | 0.917     |
|    mse                  | 117       |
| time/                   |           |
|    progress             | 1         |
|    step                 | 6e+03     |
|    step_time            | 0.677     |
---------------------------------------

Training done.
training step :2, total: 5.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:42:17,264 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:18,326 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.704 +/- 4.130
eval_results['h_violation']:[ 0  0  0  6  0  0  9 17  0  7], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]], eval_score:134.0581848554936
2023-09-05 11:42:18,330 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.672    |
|    lambda training step | 7        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0367   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0117   |
|    entropy_loss         | 1.94     |
|    policy_loss          | -0.00408 |
|    value_loss           | 0.0272   |
| stat/                   |          |
|    constraint_violation | 95       |
|    ep_constraint_vio... | 4.3      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.918    |
| stat_eval/              |          |
|    constraint_violation | 3.8      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.911    |
|    mse                  | 110      |
| time/                   |          |
|    progress             | 0.5      |
|    step                 | 3e+03    |
|    step_time            | 0.635    |
--------------------------------------

2023-09-05 11:42:21,391 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:22,454 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 133.485 +/- 5.565
eval_results['h_violation']:[11 11  0  0  0  0  8  0  0 14], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]], eval_score:130.50335792974818
2023-09-05 11:42:22,458 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.672    |
|    lambda training step | 7        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0367   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0119   |
|    entropy_loss         | 1.94     |
|    policy_loss          | -0.00807 |
|    value_loss           | 0.029    |
| stat/                   |          |
|    constraint_violation | 160      |
|    ep_constraint_vio... | 3.8      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.905    |
| stat_eval/              |          |
|    constraint_violation | 5.3      |
|    ep_length            | 150      |
|    ep_return            | 133      |
|    ep_reward            | 0.89     |
|    mse                  | 108      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 6e+03    |
|    step_time            | 0.642    |
--------------------------------------

Training done.
training step :3, total: 5.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:42:25,644 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:26,692 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.632 +/- 3.978
eval_results['h_violation']:[11  1  7 12  5 11 16  0 12  0], (eval_results['s_violation']>0):[[False]
 [ True]
 [False]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:132.56862863693826
2023-09-05 11:42:26,696 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.672    |
|    lambda training step | 7        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0367   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0227   |
|    entropy_loss         | 1.95     |
|    policy_loss          | -0.00676 |
|    value_loss           | 0.0074   |
| stat/                   |          |
|    constraint_violation | 106      |
|    ep_constraint_vio... | 5.7      |
|    ep_length            | 150      |
|    ep_return            | 134      |
|    ep_reward            | 0.897    |
| stat_eval/              |          |
|    constraint_violation | 2.9      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.918    |
|    mse                  | 105      |
| time/                   |          |
|    progress             | 0.5      |
|    step                 | 3e+03    |
|    step_time            | 0.607    |
--------------------------------------

2023-09-05 11:42:29,787 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:30,879 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 134.689 +/- 5.792
eval_results['h_violation']:[ 0  0  0 10  0  0  8 11  8 13], (eval_results['s_violation']>0):[[False]
 [False]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]], eval_score:131.30811691588667
2023-09-05 11:42:30,883 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.672    |
|    lambda training step | 7        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0367   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0715   |
|    entropy_loss         | 1.95     |
|    policy_loss          | 0.0251   |
|    value_loss           | 0.548    |
| stat/                   |          |
|    constraint_violation | 222      |
|    ep_constraint_vio... | 8.3      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.904    |
| stat_eval/              |          |
|    constraint_violation | 7.1      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.898    |
|    mse                  | 113      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 6e+03    |
|    step_time            | 0.59     |
--------------------------------------

Training done.
training step :4, total: 5.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:42:34,151 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:35,218 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.220 +/- 6.055
eval_results['h_violation']:[12  0  1  0  9  0  0  0  0  0], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [False]], eval_score:134.720064838999
2023-09-05 11:42:35,222 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.672    |
|    lambda training step | 7        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0367   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0178   |
|    entropy_loss         | 1.96     |
|    policy_loss          | 0.00701  |
|    value_loss           | 0.0195   |
| stat/                   |          |
|    constraint_violation | 112      |
|    ep_constraint_vio... | 6.1      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.902    |
| stat_eval/              |          |
|    constraint_violation | 6.8      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.908    |
|    mse                  | 116      |
| time/                   |          |
|    progress             | 0.5      |
|    step                 | 3e+03    |
|    step_time            | 0.649    |
--------------------------------------

2023-09-05 11:42:38,477 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:39,541 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.892 +/- 3.411
eval_results['h_violation']:[0 0 6 0 7 0 0 6 0 0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [ True]
 [ True]
 [ True]
 [False]], eval_score:136.58983608228652
2023-09-05 11:42:39,545 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.672    |
|    lambda training step | 7        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0367   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0413   |
|    entropy_loss         | 1.97     |
|    policy_loss          | 0.0267   |
|    value_loss           | 0.0276   |
| stat/                   |          |
|    constraint_violation | 213      |
|    ep_constraint_vio... | 6.5      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.918    |
| stat_eval/              |          |
|    constraint_violation | 4.4      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.919    |
|    mse                  | 108      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 6e+03    |
|    step_time            | 0.689    |
--------------------------------------

Training done.
training step :5, total: 5.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
Starting evaluation of constraints
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 124.162
←[33maverage_rmse←[0m: 0.567
←[33mrmse←[0m: 0.567
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.567
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 136.897
←[33maverage_rmse←[0m: 0.612
←[33mrmse←[0m: 0.612
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.612
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 135.445
←[33maverage_rmse←[0m: 0.997
←[33mrmse←[0m: 0.997
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.997
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 19.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 19.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 130.259
←[33maverage_rmse←[0m: 0.559
←[33mrmse←[0m: 0.559
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.559
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 139.811
←[33maverage_rmse←[0m: 0.641
←[33mrmse←[0m: 0.641
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.641
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 145.743
←[33maverage_rmse←[0m: 0.626
←[33mrmse←[0m: 0.626
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.626
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 131.905
←[33maverage_rmse←[0m: 0.679
←[33mrmse←[0m: 0.679
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.679
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 141.029
←[33maverage_rmse←[0m: 0.583
←[33mrmse←[0m: 0.583
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.583
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 145.337
←[33maverage_rmse←[0m: 0.722
←[33mrmse←[0m: 0.722
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.722
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 140.166
←[33maverage_rmse←[0m: 0.752
←[33mrmse←[0m: 0.752
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.752
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 132.198
←[33maverage_rmse←[0m: 0.985
←[33mrmse←[0m: 0.985
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.985
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 37.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 37.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 138.590
←[33maverage_rmse←[0m: 0.497
←[33mrmse←[0m: 0.497
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.497
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 122.238
←[33maverage_rmse←[0m: 0.908
←[33mrmse←[0m: 0.908
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.908
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 16.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 16.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 147.835
←[33maverage_rmse←[0m: 0.502
←[33mrmse←[0m: 0.502
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.502
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 147.433
←[33maverage_rmse←[0m: 0.533
←[33mrmse←[0m: 0.533
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.533
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 127.979
←[33maverage_rmse←[0m: 1.071
←[33mrmse←[0m: 1.071
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 1.071
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 27.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 27.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 141.751
←[33maverage_rmse←[0m: 0.760
←[33mrmse←[0m: 0.760
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.760
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 129.684
←[33maverage_rmse←[0m: 0.812
←[33mrmse←[0m: 0.812
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.812
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 13.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 13.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 142.794
←[33maverage_rmse←[0m: 0.730
←[33mrmse←[0m: 0.730
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.730
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 146.112
←[33maverage_rmse←[0m: 0.609
←[33mrmse←[0m: 0.609
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.609
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
Updating Lambdas: lamb_1_gradient=5.85, lamb_2_gradient=0.55
Policy update: 5th step, Lambda update: 7th step
current lambdas: (0.6717000000000001, 0.03673884290887392)
2023-09-05 11:42:46,870 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:47,938 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.566 +/- 3.619
eval_results['h_violation']:[ 8  0  0  4 17 10  7  0 11  3], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [ True]], eval_score:134.43902525705087
2023-09-05 11:42:47,942 :
---------------------------------------
| lambda/                 |           |
|    current env steps    | 6e+03     |
|    current updating ... | 1         |
|    hard_lambda          | 0.683     |
|    lambda training step | 8         |
|    policy update step   | 5         |
|    soft_lambda          | 0.0378    |
|    trajectory scale     | 0         |
| loss/                   |           |
|    approx_kl            | 0.0386    |
|    entropy_loss         | 1.96      |
|    policy_loss          | -0.000568 |
|    value_loss           | 0.0637    |
| stat/                   |           |
|    constraint_violation | 76        |
|    ep_constraint_vio... | 3.1       |
|    ep_length            | 150       |
|    ep_return            | 139       |
|    ep_reward            | 0.927     |
| stat_eval/              |           |
|    constraint_violation | 9.1       |
|    ep_length            | 150       |
|    ep_return            | 139       |
|    ep_reward            | 0.924     |
|    mse                  | 126       |
| time/                   |           |
|    progress             | 0.5       |
|    step                 | 3e+03     |
|    step_time            | 0.628     |
---------------------------------------

2023-09-05 11:42:51,163 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:52,250 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.747 +/- 2.834
eval_results['h_violation']:[ 0 17  0  4 15  0  0  8 15  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.68140459675544
2023-09-05 11:42:52,254 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.683    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0378   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0505   |
|    entropy_loss         | 1.97     |
|    policy_loss          | 0.0255   |
|    value_loss           | 0.178    |
| stat/                   |          |
|    constraint_violation | 288      |
|    ep_constraint_vio... | 10.9     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.918    |
| stat_eval/              |          |
|    constraint_violation | 7.9      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.925    |
|    mse                  | 126      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 6e+03    |
|    step_time            | 0.667    |
--------------------------------------

Training done.
training step :1, total: 5.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:42:55,699 : Checkpoint | temp/model_latest.pt
2023-09-05 11:42:56,772 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.606 +/- 4.589
eval_results['h_violation']:[7 9 8 3 9 9 8 0 7 3], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:132.26646000695064
2023-09-05 11:42:56,775 :
---------------------------------------
| lambda/                 |           |
|    current env steps    | 6e+03     |
|    current updating ... | 1         |
|    hard_lambda          | 0.683     |
|    lambda training step | 8         |
|    policy update step   | 5         |
|    soft_lambda          | 0.0378    |
|    trajectory scale     | 0         |
| loss/                   |           |
|    approx_kl            | 0.0229    |
|    entropy_loss         | 1.97      |
|    policy_loss          | -0.000113 |
|    value_loss           | 0.534     |
| stat/                   |           |
|    constraint_violation | 192       |
|    ep_constraint_vio... | 5.3       |
|    ep_length            | 150       |
|    ep_return            | 139       |
|    ep_reward            | 0.929     |
| stat_eval/              |           |
|    constraint_violation | 12.9      |
|    ep_length            | 150       |
|    ep_return            | 137       |
|    ep_reward            | 0.911     |
|    mse                  | 137       |
| time/                   |           |
|    progress             | 0.5       |
|    step                 | 3e+03     |
|    step_time            | 0.622     |
---------------------------------------

2023-09-05 11:42:59,863 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:00,936 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.320 +/- 3.093
eval_results['h_violation']:[ 0 10 13  5 12 18  8  0  6 11], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [False]
 [False]
 [ True]
 [ True]
 [False]
 [ True]
 [False]], eval_score:134.62927918924998
2023-09-05 11:43:00,940 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.683    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0378   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0529   |
|    entropy_loss         | 1.97     |
|    policy_loss          | -0.00413 |
|    value_loss           | 0.217    |
| stat/                   |          |
|    constraint_violation | 366      |
|    ep_constraint_vio... | 10.5     |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.923    |
| stat_eval/              |          |
|    constraint_violation | 8        |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.935    |
|    mse                  | 135      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 6e+03    |
|    step_time            | 0.573    |
--------------------------------------

Training done.
training step :2, total: 5.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:43:04,373 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:05,485 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.317 +/- 5.565
eval_results['h_violation']:[ 5 13  4 19 10  5 17  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [ True]], eval_score:134.29763391754398
2023-09-05 11:43:05,489 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.683    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0378   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0186   |
|    entropy_loss         | 1.98     |
|    policy_loss          | 0.00125  |
|    value_loss           | 0.575    |
| stat/                   |          |
|    constraint_violation | 234      |
|    ep_constraint_vio... | 10.5     |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.926    |
| stat_eval/              |          |
|    constraint_violation | 6.3      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.929    |
|    mse                  | 132      |
| time/                   |          |
|    progress             | 0.5      |
|    step                 | 3e+03    |
|    step_time            | 0.756    |
--------------------------------------

2023-09-05 11:43:08,729 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:09,811 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.183 +/- 5.533
eval_results['h_violation']:[15 15 13 13 15 26 12 20 15 12], (eval_results['s_violation']>0):[[False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]], eval_score:128.49503695167184
2023-09-05 11:43:09,815 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.683    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0378   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0321   |
|    entropy_loss         | 1.97     |
|    policy_loss          | -0.0074  |
|    value_loss           | 1.57     |
| stat/                   |          |
|    constraint_violation | 460      |
|    ep_constraint_vio... | 14.5     |
|    ep_length            | 128      |
|    ep_return            | 116      |
|    ep_reward            | 0.855    |
| stat_eval/              |          |
|    constraint_violation | 8.6      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.928    |
|    mse                  | 143      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 6e+03    |
|    step_time            | 0.651    |
--------------------------------------

Training done.
training step :3, total: 5.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:43:13,301 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:14,376 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.345 +/- 3.355
eval_results['h_violation']:[10  9  8 11 10 22 11 16 10 11], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:133.2465445482301
2023-09-05 11:43:14,380 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.683    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0378   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0136   |
|    entropy_loss         | 1.99     |
|    policy_loss          | -0.0103  |
|    value_loss           | 0.24     |
| stat/                   |          |
|    constraint_violation | 270      |
|    ep_constraint_vio... | 13       |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.923    |
| stat_eval/              |          |
|    constraint_violation | 7.4      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.942    |
|    mse                  | 143      |
| time/                   |          |
|    progress             | 0.5      |
|    step                 | 3e+03    |
|    step_time            | 0.691    |
--------------------------------------

2023-09-05 11:43:17,634 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:18,724 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 135.779 +/- 5.659
eval_results['h_violation']:[ 7  8  0 11  0 12  9  8  7  3], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:131.30339862100888
2023-09-05 11:43:18,727 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.683    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0378   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.018    |
|    entropy_loss         | 1.99     |
|    policy_loss          | -0.00145 |
|    value_loss           | 0.464    |
| stat/                   |          |
|    constraint_violation | 555      |
|    ep_constraint_vio... | 9.7      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.937    |
| stat_eval/              |          |
|    constraint_violation | 12.5     |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.905    |
|    mse                  | 141      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 6e+03    |
|    step_time            | 0.654    |
--------------------------------------

Training done.
training step :4, total: 5.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:43:22,002 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:23,108 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.443 +/- 6.948
eval_results['h_violation']:[ 6  0  9  2  0 13  7 16 12  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [False]
 [ True]
 [False]], eval_score:132.97445471202408
2023-09-05 11:43:23,112 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.683    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0378   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0215   |
|    entropy_loss         | 2        |
|    policy_loss          | 0.00689  |
|    value_loss           | 0.954    |
| stat/                   |          |
|    constraint_violation | 159      |
|    ep_constraint_vio... | 6.8      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
| stat_eval/              |          |
|    constraint_violation | 8.3      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.916    |
|    mse                  | 135      |
| time/                   |          |
|    progress             | 0.5      |
|    step                 | 3e+03    |
|    step_time            | 0.657    |
--------------------------------------

2023-09-05 11:43:26,323 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:27,415 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.951 +/- 6.031
eval_results['h_violation']:[12 10  1 10 17 18  0 11  0  3], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:131.31716973246472
2023-09-05 11:43:27,419 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 6e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.683    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0378   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.047    |
|    entropy_loss         | 2        |
|    policy_loss          | 0.0182   |
|    value_loss           | 0.0756   |
| stat/                   |          |
|    constraint_violation | 352      |
|    ep_constraint_vio... | 7.1      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.923    |
| stat_eval/              |          |
|    constraint_violation | 7.8      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.913    |
|    mse                  | 134      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 6e+03    |
|    step_time            | 0.627    |
--------------------------------------

Training done.
training step :5, total: 5.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
Starting evaluation of constraints
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 131.650
←[33maverage_rmse←[0m: 0.712
←[33mrmse←[0m: 0.712
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.712
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 6.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 6.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 134.090
←[33maverage_rmse←[0m: 0.680
←[33mrmse←[0m: 0.680
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.680
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 136.896
←[33maverage_rmse←[0m: 0.683
←[33mrmse←[0m: 0.683
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.683
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 141.340
←[33maverage_rmse←[0m: 0.514
←[33mrmse←[0m: 0.514
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.514
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 139.667
←[33maverage_rmse←[0m: 1.472
←[33mrmse←[0m: 1.472
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 1.472
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 64.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 64.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 141.605
←[33maverage_rmse←[0m: 0.863
←[33mrmse←[0m: 0.863
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.863
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 145.359
←[33maverage_rmse←[0m: 0.726
←[33mrmse←[0m: 0.726
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.726
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 31.000
←[33mlength←[0m: 31.000
←[33maverage_return←[0m: 18.999
←[33maverage_rmse←[0m: 2.401
←[33mrmse←[0m: 2.401
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 2.401
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 21.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 21.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 142.528
←[33maverage_rmse←[0m: 0.834
←[33mrmse←[0m: 0.834
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.834
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 146.043
←[33maverage_rmse←[0m: 0.693
←[33mrmse←[0m: 0.693
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.693
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 142.921
←[33maverage_rmse←[0m: 0.820
←[33mrmse←[0m: 0.820
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.820
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 27.000
←[33mlength←[0m: 27.000
←[33maverage_return←[0m: 13.916
←[33maverage_rmse←[0m: 2.300
←[33mrmse←[0m: 2.300
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 2.300
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 20.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 20.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 139.357
←[33maverage_rmse←[0m: 1.026
←[33mrmse←[0m: 1.026
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 1.026
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 16.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 16.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 147.716
←[33maverage_rmse←[0m: 0.573
←[33mrmse←[0m: 0.573
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.573
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 147.907
←[33maverage_rmse←[0m: 0.551
←[33mrmse←[0m: 0.551
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.551
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 142.995
←[33maverage_rmse←[0m: 0.818
←[33mrmse←[0m: 0.818
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.818
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 142.394
←[33maverage_rmse←[0m: 0.838
←[33mrmse←[0m: 0.838
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.838
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 141.928
←[33maverage_rmse←[0m: 1.033
←[33mrmse←[0m: 1.033
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 1.033
←[33mfailure_rate←[0m: 1.000
←[33maverage_constraint_violation←[0m: 24.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 24.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 134.870
←[33maverage_rmse←[0m: 0.730
←[33mrmse←[0m: 0.730
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.730
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 138.935
←[33maverage_rmse←[0m: 0.794
←[33mrmse←[0m: 0.794
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.794
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
Updating Lambdas: lamb_1_gradient=7.9, lamb_2_gradient=0.7
Policy update: 5th step, Lambda update: 8th step
current lambdas: (0.6834000000000001, 0.03776354930121271)
2023-09-05 11:43:34,497 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:35,598 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.574 +/- 1.879
eval_results['h_violation']:[ 0  3  0 19  0  0  0 14  0 22], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]], eval_score:137.4910709106897
2023-09-05 11:43:35,602 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0225   |
|    entropy_loss         | 2.01     |
|    policy_loss          | -0.00258 |
|    value_loss           | 0.064    |
| stat/                   |          |
|    constraint_violation | 153      |
|    ep_constraint_vio... | 11.2     |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.907    |
| stat_eval/              |          |
|    constraint_violation | 3        |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.944    |
|    mse                  | 122      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.651    |
--------------------------------------

Training done.
training step :1, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:43:38,969 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:40,088 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.154 +/- 4.944
eval_results['h_violation']:[ 4 23 25  9  0  4  0  9  8  5], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]], eval_score:133.04356099010104
2023-09-05 11:43:40,092 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0278   |
|    entropy_loss         | 2        |
|    policy_loss          | 0.00492  |
|    value_loss           | 0.135    |
| stat/                   |          |
|    constraint_violation | 86       |
|    ep_constraint_vio... | 4.4      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.929    |
| stat_eval/              |          |
|    constraint_violation | 5.7      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.928    |
|    mse                  | 130      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.679    |
--------------------------------------

Training done.
training step :2, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:43:43,390 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:44,469 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.541 +/- 4.291
eval_results['h_violation']:[ 0  0  0  0 22  0 11  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]], eval_score:135.2022942729123
2023-09-05 11:43:44,473 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0135   |
|    entropy_loss         | 1.99     |
|    policy_loss          | 0.0022   |
|    value_loss           | 0.117    |
| stat/                   |          |
|    constraint_violation | 117      |
|    ep_constraint_vio... | 4.1      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.926    |
| stat_eval/              |          |
|    constraint_violation | 4.2      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.917    |
|    mse                  | 117      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.65     |
--------------------------------------

Training done.
training step :3, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:43:47,929 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:49,059 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.245 +/- 2.084
eval_results['h_violation']:[ 0  0  0  0  0  0  0 14  0  0], (eval_results['s_violation']>0):[[False]
 [False]
 [False]
 [ True]
 [ True]
 [False]
 [False]
 [ True]
 [ True]
 [ True]], eval_score:139.2467129375943
2023-09-05 11:43:49,063 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0258   |
|    entropy_loss         | 2        |
|    policy_loss          | 0.00478  |
|    value_loss           | 0.0344   |
| stat/                   |          |
|    constraint_violation | 113      |
|    ep_constraint_vio... | 4.4      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.917    |
| stat_eval/              |          |
|    constraint_violation | 1.3      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.935    |
|    mse                  | 107      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.682    |
--------------------------------------

Training done.
training step :4, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:43:52,299 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:53,368 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.559 +/- 3.569
eval_results['h_violation']:[0 0 0 0 7 0 8 0 0 0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [False]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.4787465218451
2023-09-05 11:43:53,372 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0458   |
|    entropy_loss         | 2.01     |
|    policy_loss          | 0.00746  |
|    value_loss           | 0.0499   |
| stat/                   |          |
|    constraint_violation | 106      |
|    ep_constraint_vio... | 5.8      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.926    |
| stat_eval/              |          |
|    constraint_violation | 8.2      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.924    |
|    mse                  | 129      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.6      |
--------------------------------------

Training done.
training step :5, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:43:56,727 : Checkpoint | temp/model_latest.pt
2023-09-05 11:43:57,773 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.077 +/- 5.537
eval_results['h_violation']:[ 0  0  0  0 13  5  0 15  0  0], (eval_results['s_violation']>0):[[False]
 [False]
 [False]
 [False]
 [ True]
 [ True]
 [False]
 [False]
 [ True]
 [ True]], eval_score:138.75395591388863
2023-09-05 11:43:57,776 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.012    |
|    entropy_loss         | 2        |
|    policy_loss          | 0.000545 |
|    value_loss           | 0.0615   |
| stat/                   |          |
|    constraint_violation | 210      |
|    ep_constraint_vio... | 8.8      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.92     |
| stat_eval/              |          |
|    constraint_violation | 4.4      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.941    |
|    mse                  | 125      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.714    |
--------------------------------------

Training done.
training step :6, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:01,120 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:02,246 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.787 +/- 4.835
eval_results['h_violation']:[12  4  9  4 11 13  4 27 11  4], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.82533837340856
2023-09-05 11:44:02,249 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0244   |
|    entropy_loss         | 2.02     |
|    policy_loss          | 0.0132   |
|    value_loss           | 1.65     |
| stat/                   |          |
|    constraint_violation | 234      |
|    ep_constraint_vio... | 14.2     |
|    ep_length            | 138      |
|    ep_return            | 127      |
|    ep_reward            | 0.882    |
| stat_eval/              |          |
|    constraint_violation | 4.8      |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.945    |
|    mse                  | 137      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.665    |
--------------------------------------

Training done.
training step :7, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:05,684 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:06,755 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.289 +/- 5.460
eval_results['h_violation']:[ 3  1  0  8  7  0  0  0 22  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.38315754596377
2023-09-05 11:44:06,758 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.304    |
|    entropy_loss         | 2.02     |
|    policy_loss          | 0.0506   |
|    value_loss           | 0.0797   |
| stat/                   |          |
|    constraint_violation | 166      |
|    ep_constraint_vio... | 8.9      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
| stat_eval/              |          |
|    constraint_violation | 7.9      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.915    |
|    mse                  | 125      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.608    |
--------------------------------------

Training done.
training step :8, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:09,914 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:10,841 : Eval | ep_lengths 125.70 +/- 48.60 | ep_return 113.210 +/- 48.879
eval_results['h_violation']:[ 8 10  0 18  0 11  5  0 19  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:108.20685388794807
2023-09-05 11:44:10,845 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.016    |
|    entropy_loss         | 2.03     |
|    policy_loss          | -0.00141 |
|    value_loss           | 0.632    |
| stat/                   |          |
|    constraint_violation | 165      |
|    ep_constraint_vio... | 7.6      |
|    ep_length            | 138      |
|    ep_return            | 123      |
|    ep_reward            | 0.875    |
| stat_eval/              |          |
|    constraint_violation | 6        |
|    ep_length            | 126      |
|    ep_return            | 113      |
|    ep_reward            | 0.844    |
|    mse                  | 121      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.651    |
--------------------------------------

Training done.
training step :9, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:14,158 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:15,059 : Eval | ep_lengths 126.30 +/- 47.41 | ep_return 112.011 +/- 46.553
eval_results['h_violation']:[ 0 10  6 21  7 16  7  6  7 14], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:105.39933554589481
2023-09-05 11:44:15,062 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0576   |
|    entropy_loss         | 2.03     |
|    policy_loss          | -0.00211 |
|    value_loss           | 3.68     |
| stat/                   |          |
|    constraint_violation | 274      |
|    ep_constraint_vio... | 18.9     |
|    ep_length            | 107      |
|    ep_return            | 86.6     |
|    ep_reward            | 0.738    |
| stat_eval/              |          |
|    constraint_violation | 9        |
|    ep_length            | 126      |
|    ep_return            | 112      |
|    ep_reward            | 0.841    |
|    mse                  | 126      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.593    |
--------------------------------------

Training done.
training step :10, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:18,333 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:19,430 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 131.327 +/- 7.125
eval_results['h_violation']:[22 15  0  0  0  0 13  0  3 25], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:125.8336575487499
2023-09-05 11:44:19,434 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0572   |
|    entropy_loss         | 2.03     |
|    policy_loss          | 0.0227   |
|    value_loss           | 1.3      |
| stat/                   |          |
|    constraint_violation | 70       |
|    ep_constraint_vio... | 4.3      |
|    ep_length            | 150      |
|    ep_return            | 130      |
|    ep_reward            | 0.869    |
| stat_eval/              |          |
|    constraint_violation | 3.3      |
|    ep_length            | 150      |
|    ep_return            | 131      |
|    ep_reward            | 0.876    |
|    mse                  | 99.7     |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.643    |
--------------------------------------

Training done.
training step :11, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:22,781 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:23,841 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 130.068 +/- 6.155
eval_results['h_violation']:[18 16  0 10  0  0 21  0  0 12], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:124.64511622228403
2023-09-05 11:44:23,845 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0142   |
|    entropy_loss         | 2.03     |
|    policy_loss          | -0.00404 |
|    value_loss           | 0.448    |
| stat/                   |          |
|    constraint_violation | 100      |
|    ep_constraint_vio... | 3.2      |
|    ep_length            | 150      |
|    ep_return            | 131      |
|    ep_reward            | 0.872    |
| stat_eval/              |          |
|    constraint_violation | 6.5      |
|    ep_length            | 150      |
|    ep_return            | 130      |
|    ep_reward            | 0.867    |
|    mse                  | 104      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.615    |
--------------------------------------

Training done.
training step :12, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:27,308 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:28,464 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 126.647 +/- 6.106
eval_results['h_violation']:[ 0  0 18 12  0  0  0 14  4  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:123.2516273104897
2023-09-05 11:44:28,468 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0204   |
|    entropy_loss         | 2.03     |
|    policy_loss          | 0.0115   |
|    value_loss           | 0.0961   |
| stat/                   |          |
|    constraint_violation | 44       |
|    ep_constraint_vio... | 3.2      |
|    ep_length            | 150      |
|    ep_return            | 131      |
|    ep_reward            | 0.872    |
| stat_eval/              |          |
|    constraint_violation | 8.5      |
|    ep_length            | 150      |
|    ep_return            | 127      |
|    ep_reward            | 0.844    |
|    mse                  | 104      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.72     |
--------------------------------------

Training done.
training step :13, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:31,895 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:33,010 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 129.305 +/- 6.238
eval_results['h_violation']:[ 0  0 11  4  0  0 23  0  1 15], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:125.49000050130518
2023-09-05 11:44:33,014 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0428   |
|    entropy_loss         | 2.04     |
|    policy_loss          | -0.0101  |
|    value_loss           | 0.6      |
| stat/                   |          |
|    constraint_violation | 131      |
|    ep_constraint_vio... | 5.2      |
|    ep_length            | 150      |
|    ep_return            | 128      |
|    ep_reward            | 0.856    |
| stat_eval/              |          |
|    constraint_violation | 7.9      |
|    ep_length            | 150      |
|    ep_return            | 129      |
|    ep_reward            | 0.862    |
|    mse                  | 104      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.676    |
--------------------------------------

Training done.
training step :14, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:36,511 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:37,598 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 128.465 +/- 7.181
eval_results['h_violation']:[ 4  7  0  7  0  0  0  0  0 10], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:126.468005365825
2023-09-05 11:44:37,602 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.025    |
|    entropy_loss         | 2.04     |
|    policy_loss          | 0.0126   |
|    value_loss           | 0.527    |
| stat/                   |          |
|    constraint_violation | 100      |
|    ep_constraint_vio... | 6.2      |
|    ep_length            | 150      |
|    ep_return            | 130      |
|    ep_reward            | 0.869    |
| stat_eval/              |          |
|    constraint_violation | 8.1      |
|    ep_length            | 150      |
|    ep_return            | 128      |
|    ep_reward            | 0.856    |
|    mse                  | 105      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.659    |
--------------------------------------

Training done.
training step :15, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:41,045 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:42,116 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 133.382 +/- 5.234
eval_results['h_violation']:[ 5 13  0  4  0  0  0  0  0 10], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:131.1059515076902
2023-09-05 11:44:42,120 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0115   |
|    entropy_loss         | 2.04     |
|    policy_loss          | -0.00101 |
|    value_loss           | 0.594    |
| stat/                   |          |
|    constraint_violation | 251      |
|    ep_constraint_vio... | 8.5      |
|    ep_length            | 139      |
|    ep_return            | 121      |
|    ep_reward            | 0.848    |
| stat_eval/              |          |
|    constraint_violation | 3        |
|    ep_length            | 150      |
|    ep_return            | 133      |
|    ep_reward            | 0.889    |
|    mse                  | 94.9     |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.657    |
--------------------------------------

Training done.
training step :16, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:45,354 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:46,423 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 127.823 +/- 8.367
eval_results['h_violation']:[ 4  8 16 11  0  0  0  0  7 11], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:123.79879348513116
2023-09-05 11:44:46,426 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0234   |
|    entropy_loss         | 2.05     |
|    policy_loss          | -0.00218 |
|    value_loss           | 0.475    |
| stat/                   |          |
|    constraint_violation | 91       |
|    ep_constraint_vio... | 6.8      |
|    ep_length            | 150      |
|    ep_return            | 128      |
|    ep_reward            | 0.852    |
| stat_eval/              |          |
|    constraint_violation | 4.9      |
|    ep_length            | 150      |
|    ep_return            | 128      |
|    ep_reward            | 0.852    |
|    mse                  | 102      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.638    |
--------------------------------------

Training done.
training step :17, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:49,802 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:50,866 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 134.533 +/- 6.842
eval_results['h_violation']:[20 13  5 16 13  0  0  0  2  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:129.66905615286348
2023-09-05 11:44:50,869 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0192   |
|    entropy_loss         | 2.05     |
|    policy_loss          | 0.00788  |
|    value_loss           | 1.05     |
| stat/                   |          |
|    constraint_violation | 118      |
|    ep_constraint_vio... | 5.7      |
|    ep_length            | 150      |
|    ep_return            | 131      |
|    ep_reward            | 0.874    |
| stat_eval/              |          |
|    constraint_violation | 4        |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.897    |
|    mse                  | 107      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.606    |
--------------------------------------

Training done.
training step :18, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:54,120 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:55,238 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 135.297 +/- 6.478
eval_results['h_violation']:[ 0  0  0  0 24  0  0  0 10 17], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:131.69177632140523
2023-09-05 11:44:55,242 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0234   |
|    entropy_loss         | 2.05     |
|    policy_loss          | -0.00329 |
|    value_loss           | 0.118    |
| stat/                   |          |
|    constraint_violation | 71       |
|    ep_constraint_vio... | 5        |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.91     |
| stat_eval/              |          |
|    constraint_violation | 5.5      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.902    |
|    mse                  | 110      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.666    |
--------------------------------------

Training done.
training step :19, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:44:58,532 : Checkpoint | temp/model_latest.pt
2023-09-05 11:44:59,605 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.438 +/- 4.826
eval_results['h_violation']:[ 0  0  0  0 16  0  0  0  4  7], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.51098890245035
2023-09-05 11:44:59,609 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.057    |
|    entropy_loss         | 2.07     |
|    policy_loss          | 0.00438  |
|    value_loss           | 0.0658   |
| stat/                   |          |
|    constraint_violation | 112      |
|    ep_constraint_vio... | 5.7      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.903    |
| stat_eval/              |          |
|    constraint_violation | 4        |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.91     |
|    mse                  | 107      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.585    |
--------------------------------------

Training done.
training step :20, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:02,898 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:03,942 : Eval | ep_lengths 140.40 +/- 28.80 | ep_return 119.298 +/- 34.897
eval_results['h_violation']:[10  0 14  0 10  3  0  0 31  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:114.50446837461936
2023-09-05 11:45:03,947 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0376   |
|    entropy_loss         | 2.07     |
|    policy_loss          | -0.0126  |
|    value_loss           | 0.591    |
| stat/                   |          |
|    constraint_violation | 151      |
|    ep_constraint_vio... | 6.7      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.907    |
| stat_eval/              |          |
|    constraint_violation | 16.5     |
|    ep_length            | 140      |
|    ep_return            | 119      |
|    ep_reward            | 0.814    |
|    mse                  | 147      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.631    |
--------------------------------------

Training done.
training step :21, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:07,686 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:08,842 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 135.349 +/- 5.830
eval_results['h_violation']:[14  5 20  0  3  0  7 11  0 10], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:130.41576840403332
2023-09-05 11:45:08,845 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0341   |
|    entropy_loss         | 2.07     |
|    policy_loss          | -0.0038  |
|    value_loss           | 0.567    |
| stat/                   |          |
|    constraint_violation | 149      |
|    ep_constraint_vio... | 12.1     |
|    ep_length            | 150      |
|    ep_return            | 134      |
|    ep_reward            | 0.89     |
| stat_eval/              |          |
|    constraint_violation | 9.7      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.902    |
|    mse                  | 127      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.681    |
--------------------------------------

Training done.
training step :22, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:12,153 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:13,227 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 134.515 +/- 6.476
eval_results['h_violation']:[ 5 10  4  0  0 12 14 15  0 18], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:129.02171371498667
2023-09-05 11:45:13,230 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0318   |
|    entropy_loss         | 2.07     |
|    policy_loss          | -0.00577 |
|    value_loss           | 0.123    |
| stat/                   |          |
|    constraint_violation | 163      |
|    ep_constraint_vio... | 4.2      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.922    |
| stat_eval/              |          |
|    constraint_violation | 5.1      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.897    |
|    mse                  | 115      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.603    |
--------------------------------------

Training done.
training step :23, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:16,505 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:17,570 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 132.913 +/- 5.446
eval_results['h_violation']:[0 9 0 0 4 0 0 0 0 6], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:131.54560451246599
2023-09-05 11:45:17,574 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0329   |
|    entropy_loss         | 2.07     |
|    policy_loss          | 0.00735  |
|    value_loss           | 0.0524   |
| stat/                   |          |
|    constraint_violation | 112      |
|    ep_constraint_vio... | 4.6      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.901    |
| stat_eval/              |          |
|    constraint_violation | 5.1      |
|    ep_length            | 150      |
|    ep_return            | 133      |
|    ep_reward            | 0.886    |
|    mse                  | 101      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.626    |
--------------------------------------

Training done.
training step :24, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:20,947 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:22,021 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 135.788 +/- 3.074
eval_results['h_violation']:[0 0 3 0 0 0 3 0 0 0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [False]
 [ True]
 [ True]
 [False]
 [False]
 [False]
 [ True]
 [ True]], eval_score:135.3448314692599
2023-09-05 11:45:22,025 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0156   |
|    entropy_loss         | 2.08     |
|    policy_loss          | -0.00283 |
|    value_loss           | 0.0459   |
| stat/                   |          |
|    constraint_violation | 56       |
|    ep_constraint_vio... | 2.8      |
|    ep_length            | 150      |
|    ep_return            | 133      |
|    ep_reward            | 0.889    |
| stat_eval/              |          |
|    constraint_violation | 1.5      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.905    |
|    mse                  | 88.5     |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.673    |
--------------------------------------

Training done.
training step :25, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:25,457 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:26,537 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 135.584 +/- 5.433
eval_results['h_violation']:[ 9  0  0  0  0 13  0  0  5  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:133.65742084887506
2023-09-05 11:45:26,541 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0313   |
|    entropy_loss         | 2.09     |
|    policy_loss          | -0.00692 |
|    value_loss           | 0.047    |
| stat/                   |          |
|    constraint_violation | 64       |
|    ep_constraint_vio... | 2.1      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.909    |
| stat_eval/              |          |
|    constraint_violation | 2.8      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.904    |
|    mse                  | 101      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.624    |
--------------------------------------

Training done.
training step :26, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:29,920 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:30,998 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 134.251 +/- 6.397
eval_results['h_violation']:[ 0  0  0 19 18  0  0 14  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:130.65003733605587
2023-09-05 11:45:31,001 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0412   |
|    entropy_loss         | 2.08     |
|    policy_loss          | 0.00705  |
|    value_loss           | 0.0315   |
| stat/                   |          |
|    constraint_violation | 94       |
|    ep_constraint_vio... | 5.6      |
|    ep_length            | 150      |
|    ep_return            | 134      |
|    ep_reward            | 0.894    |
| stat_eval/              |          |
|    constraint_violation | 8.5      |
|    ep_length            | 150      |
|    ep_return            | 134      |
|    ep_reward            | 0.895    |
|    mse                  | 121      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.663    |
--------------------------------------

Training done.
training step :27, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:34,236 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:35,305 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.254 +/- 6.192
eval_results['h_violation']:[17 11  0  0  0 13  0 19  0  8], (eval_results['s_violation']>0):[[ True]
 [ True]
 [False]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:133.4686469331214
2023-09-05 11:45:35,309 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0368   |
|    entropy_loss         | 2.08     |
|    policy_loss          | 0.00709  |
|    value_loss           | 0.0529   |
| stat/                   |          |
|    constraint_violation | 113      |
|    ep_constraint_vio... | 6.2      |
|    ep_length            | 150      |
|    ep_return            | 134      |
|    ep_reward            | 0.895    |
| stat_eval/              |          |
|    constraint_violation | 2.6      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.922    |
|    mse                  | 116      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.612    |
--------------------------------------

Training done.
training step :28, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:38,466 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:39,534 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.883 +/- 6.811
eval_results['h_violation']:[ 0  0 10  6  7  0  8  0  0 22], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [False]
 [ True]], eval_score:134.15357090601051
2023-09-05 11:45:39,538 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.112    |
|    entropy_loss         | 2.09     |
|    policy_loss          | 0.0297   |
|    value_loss           | 0.0337   |
| stat/                   |          |
|    constraint_violation | 74       |
|    ep_constraint_vio... | 3.5      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.906    |
| stat_eval/              |          |
|    constraint_violation | 3.5      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.919    |
|    mse                  | 124      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.58     |
--------------------------------------

Training done.
training step :29, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:43,039 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:44,094 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.429 +/- 5.137
eval_results['h_violation']:[ 0  0  5  0 22  0  1  3  0  0], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [False]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:135.23369063289368
2023-09-05 11:45:44,098 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0563   |
|    entropy_loss         | 2.09     |
|    policy_loss          | 0.018    |
|    value_loss           | 0.0255   |
| stat/                   |          |
|    constraint_violation | 89       |
|    ep_constraint_vio... | 4.9      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.918    |
| stat_eval/              |          |
|    constraint_violation | 4.7      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.916    |
|    mse                  | 120      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.632    |
--------------------------------------

Training done.
training step :30, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:47,446 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:48,522 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.797 +/- 4.129
eval_results['h_violation']:[23 23  8 24  0  0  0  0  3  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.0986124383372
2023-09-05 11:45:48,525 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0205   |
|    entropy_loss         | 2.1      |
|    policy_loss          | 0.00449  |
|    value_loss           | 0.0256   |
| stat/                   |          |
|    constraint_violation | 79       |
|    ep_constraint_vio... | 3.2      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.925    |
| stat_eval/              |          |
|    constraint_violation | 3.9      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
|    mse                  | 119      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.659    |
--------------------------------------

Training done.
training step :31, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:52,015 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:53,097 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 135.275 +/- 6.919
eval_results['h_violation']:[ 1  0  0  0  0  9 10  0 11  4], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:132.79682613430487
2023-09-05 11:45:53,101 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0571   |
|    entropy_loss         | 2.1      |
|    policy_loss          | 0.012    |
|    value_loss           | 0.0222   |
| stat/                   |          |
|    constraint_violation | 77       |
|    ep_constraint_vio... | 3        |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.924    |
| stat_eval/              |          |
|    constraint_violation | 4.3      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.902    |
|    mse                  | 117      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.643    |
--------------------------------------

Training done.
training step :32, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:45:56,407 : Checkpoint | temp/model_latest.pt
2023-09-05 11:45:57,489 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 132.324 +/- 6.146
eval_results['h_violation']:[ 0  0 10 10  4 10 10  0  5 11], (eval_results['s_violation']>0):[[False]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]], eval_score:128.101509721301
2023-09-05 11:45:57,493 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.167    |
|    entropy_loss         | 2.1      |
|    policy_loss          | 0.0756   |
|    value_loss           | 0.0261   |
| stat/                   |          |
|    constraint_violation | 74       |
|    ep_constraint_vio... | 4.5      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.906    |
| stat_eval/              |          |
|    constraint_violation | 4.4      |
|    ep_length            | 150      |
|    ep_return            | 132      |
|    ep_reward            | 0.882    |
|    mse                  | 103      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.625    |
--------------------------------------

Training done.
training step :33, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:00,818 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:01,917 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.281 +/- 3.116
eval_results['h_violation']:[ 0  0  0  0  4  0  0 13  6  0], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [False]
 [ True]
 [ True]
 [ True]], eval_score:134.6490949017746
2023-09-05 11:46:01,921 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.082    |
|    entropy_loss         | 2.11     |
|    policy_loss          | 0.0197   |
|    value_loss           | 0.0301   |
| stat/                   |          |
|    constraint_violation | 40       |
|    ep_constraint_vio... | 1.6      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.907    |
| stat_eval/              |          |
|    constraint_violation | 1.8      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.909    |
|    mse                  | 95.5     |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.624    |
--------------------------------------

Training done.
training step :34, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:05,207 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:06,291 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.428 +/- 4.215
eval_results['h_violation']:[ 0  0 11 12  0  0  5  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]], eval_score:134.43929158409063
2023-09-05 11:46:06,294 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0611   |
|    entropy_loss         | 2.11     |
|    policy_loss          | 0.00425  |
|    value_loss           | 0.0275   |
| stat/                   |          |
|    constraint_violation | 71       |
|    ep_constraint_vio... | 3.2      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.901    |
| stat_eval/              |          |
|    constraint_violation | 4.4      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.91     |
|    mse                  | 111      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.61     |
--------------------------------------

Training done.
training step :35, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:09,531 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:10,613 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.062 +/- 4.653
eval_results['h_violation']:[ 0 10  0  6  0  0  0 16  0  5], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]], eval_score:133.4441807634767
2023-09-05 11:46:10,617 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0163   |
|    entropy_loss         | 2.11     |
|    policy_loss          | -0.00491 |
|    value_loss           | 0.029    |
| stat/                   |          |
|    constraint_violation | 83       |
|    ep_constraint_vio... | 5.5      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.908    |
| stat_eval/              |          |
|    constraint_violation | 4.4      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.907    |
|    mse                  | 113      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.663    |
--------------------------------------

Training done.
training step :36, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:13,949 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:15,022 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.383 +/- 5.147
eval_results['h_violation']:[ 6  0  0 15  0  4  0  0  9 15], (eval_results['s_violation']>0):[[ True]
 [False]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:132.92928509176525
2023-09-05 11:46:15,026 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0171   |
|    entropy_loss         | 2.11     |
|    policy_loss          | 0.00164  |
|    value_loss           | 0.0165   |
| stat/                   |          |
|    constraint_violation | 83       |
|    ep_constraint_vio... | 3.6      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.905    |
| stat_eval/              |          |
|    constraint_violation | 3        |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.909    |
|    mse                  | 114      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.641    |
--------------------------------------

Training done.
training step :37, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:18,228 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:19,284 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.919 +/- 3.753
eval_results['h_violation']:[11  0  0 19  0  0  0  0  6  0], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.36689367404622
2023-09-05 11:46:19,288 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0309   |
|    entropy_loss         | 2.11     |
|    policy_loss          | -0.00341 |
|    value_loss           | 0.191    |
| stat/                   |          |
|    constraint_violation | 78       |
|    ep_constraint_vio... | 3.6      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.917    |
| stat_eval/              |          |
|    constraint_violation | 3.1      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.913    |
|    mse                  | 121      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.596    |
--------------------------------------

Training done.
training step :38, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:22,498 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:23,554 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.175 +/- 5.130
eval_results['h_violation']:[ 9  6  6  7 19  0 10  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [False]
 [False]
 [False]
 [False]], eval_score:136.17033462228218
2023-09-05 11:46:23,557 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0335   |
|    entropy_loss         | 2.11     |
|    policy_loss          | 0.014    |
|    value_loss           | 0.0172   |
| stat/                   |          |
|    constraint_violation | 79       |
|    ep_constraint_vio... | 4.8      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.898    |
| stat_eval/              |          |
|    constraint_violation | 1.5      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.935    |
|    mse                  | 117      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.649    |
--------------------------------------

Training done.
training step :39, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:26,765 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:27,841 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.891 +/- 4.888
eval_results['h_violation']:[8 0 0 0 1 9 6 0 0 8], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]], eval_score:135.62261766765118
2023-09-05 11:46:27,845 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.014    |
|    entropy_loss         | 2.11     |
|    policy_loss          | 0.00184  |
|    value_loss           | 0.0238   |
| stat/                   |          |
|    constraint_violation | 86       |
|    ep_constraint_vio... | 4.3      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.902    |
| stat_eval/              |          |
|    constraint_violation | 3        |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.919    |
|    mse                  | 121      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.643    |
--------------------------------------

Training done.
training step :40, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:31,080 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:32,153 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.098 +/- 6.153
eval_results['h_violation']:[ 0  0  0 15  0 12 11 14 11  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]], eval_score:133.65794958660857
2023-09-05 11:46:32,157 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0474   |
|    entropy_loss         | 2.11     |
|    policy_loss          | 0.00939  |
|    value_loss           | 1.35     |
| stat/                   |          |
|    constraint_violation | 73       |
|    ep_constraint_vio... | 3.1      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.942    |
| stat_eval/              |          |
|    constraint_violation | 5.4      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.921    |
|    mse                  | 134      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.626    |
--------------------------------------

Training done.
training step :41, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:35,473 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:36,559 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.748 +/- 6.512
eval_results['h_violation']:[ 6  0  0 10  0  0  0  0 12  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:135.75528694026522
2023-09-05 11:46:36,563 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0233   |
|    entropy_loss         | 2.12     |
|    policy_loss          | 0.00411  |
|    value_loss           | 0.0527   |
| stat/                   |          |
|    constraint_violation | 96       |
|    ep_constraint_vio... | 3.7      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.935    |
| stat_eval/              |          |
|    constraint_violation | 5.4      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.918    |
|    mse                  | 135      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.66     |
--------------------------------------

Training done.
training step :42, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:39,933 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:41,018 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.556 +/- 3.653
eval_results['h_violation']:[0 0 5 0 0 0 0 0 0 0], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:139.17090264694914
2023-09-05 11:46:41,022 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0208   |
|    entropy_loss         | 2.13     |
|    policy_loss          | 0.00734  |
|    value_loss           | 0.0249   |
| stat/                   |          |
|    constraint_violation | 110      |
|    ep_constraint_vio... | 6.5      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.929    |
| stat_eval/              |          |
|    constraint_violation | 2.7      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.93     |
|    mse                  | 130      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.695    |
--------------------------------------

Training done.
training step :43, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:44,341 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:45,404 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.025 +/- 5.374
eval_results['h_violation']:[0 0 0 0 7 0 0 7 6 0], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [False]
 [ True]
 [False]
 [ True]], eval_score:135.60348244406902
2023-09-05 11:46:45,407 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0681   |
|    entropy_loss         | 2.13     |
|    policy_loss          | 0.00517  |
|    value_loss           | 0.0252   |
| stat/                   |          |
|    constraint_violation | 105      |
|    ep_constraint_vio... | 4.4      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.924    |
| stat_eval/              |          |
|    constraint_violation | 4.9      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.914    |
|    mse                  | 128      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.602    |
--------------------------------------

Training done.
training step :44, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:48,549 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:49,622 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.165 +/- 4.032
eval_results['h_violation']:[ 3  4  4  0  0  8  0 18 18  0], (eval_results['s_violation']>0):[[False]
 [False]
 [False]
 [ True]
 [False]
 [ True]
 [False]
 [False]
 [ True]
 [ True]], eval_score:137.30340781588518
2023-09-05 11:46:49,626 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0349   |
|    entropy_loss         | 2.13     |
|    policy_loss          | 0.0037   |
|    value_loss           | 0.0949   |
| stat/                   |          |
|    constraint_violation | 103      |
|    ep_constraint_vio... | 5.7      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.923    |
| stat_eval/              |          |
|    constraint_violation | 2.1      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.941    |
|    mse                  | 130      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.613    |
--------------------------------------

Training done.
training step :45, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:52,928 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:54,045 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.277 +/- 4.788
eval_results['h_violation']:[ 0 14  0  0  5  4  8  6  2  0], (eval_results['s_violation']>0):[[False]
 [False]
 [ True]
 [False]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]], eval_score:136.5307960357965
2023-09-05 11:46:54,050 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0943   |
|    entropy_loss         | 2.13     |
|    policy_loss          | 0.034    |
|    value_loss           | 0.263    |
| stat/                   |          |
|    constraint_violation | 202      |
|    ep_constraint_vio... | 9.6      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.905    |
| stat_eval/              |          |
|    constraint_violation | 3.8      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.929    |
|    mse                  | 125      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.617    |
--------------------------------------

Training done.
training step :46, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:46:57,412 : Checkpoint | temp/model_latest.pt
2023-09-05 11:46:58,509 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.661 +/- 2.911
eval_results['h_violation']:[ 7  4  6  7 18  0  5  0 17  9], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [False]
 [False]
 [False]
 [ True]], eval_score:136.5370287123471
2023-09-05 11:46:58,513 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0387   |
|    entropy_loss         | 2.13     |
|    policy_loss          | 0.00801  |
|    value_loss           | 0.714    |
| stat/                   |          |
|    constraint_violation | 128      |
|    ep_constraint_vio... | 7.2      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.924    |
| stat_eval/              |          |
|    constraint_violation | 2.7      |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.944    |
|    mse                  | 133      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.619    |
--------------------------------------

Training done.
training step :47, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:01,881 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:02,975 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.524 +/- 3.262
eval_results['h_violation']:[ 4 15  4  0  9  0  9  7  7  9], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:135.00959261178082
2023-09-05 11:47:02,979 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0686   |
|    entropy_loss         | 2.13     |
|    policy_loss          | 0.0217   |
|    value_loss           | 0.0286   |
| stat/                   |          |
|    constraint_violation | 193      |
|    ep_constraint_vio... | 9.8      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
| stat_eval/              |          |
|    constraint_violation | 13.9     |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.93     |
|    mse                  | 143      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.669    |
--------------------------------------

Training done.
training step :48, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:06,404 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:07,473 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.488 +/- 4.160
eval_results['h_violation']:[8 0 0 3 4 0 0 7 6 7], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:136.001900500883
2023-09-05 11:47:07,477 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0245   |
|    entropy_loss         | 2.13     |
|    policy_loss          | -0.00301 |
|    value_loss           | 0.0465   |
| stat/                   |          |
|    constraint_violation | 262      |
|    ep_constraint_vio... | 13.4     |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.925    |
| stat_eval/              |          |
|    constraint_violation | 14       |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.923    |
|    mse                  | 146      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.628    |
--------------------------------------

Training done.
training step :49, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:10,891 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:11,983 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.369 +/- 5.166
eval_results['h_violation']:[ 0  0  8  5  0  8  0  0 17  6], (eval_results['s_violation']>0):[[False]
 [ True]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:135.26470583839753
2023-09-05 11:47:11,986 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.025    |
|    entropy_loss         | 2.15     |
|    policy_loss          | 0.00869  |
|    value_loss           | 2.05     |
| stat/                   |          |
|    constraint_violation | 250      |
|    ep_constraint_vio... | 12       |
|    ep_length            | 138      |
|    ep_return            | 125      |
|    ep_reward            | 0.876    |
| stat_eval/              |          |
|    constraint_violation | 4.1      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.922    |
|    mse                  | 127      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.649    |
--------------------------------------

Training done.
training step :50, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:15,498 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:16,577 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 142.651 +/- 0.856
eval_results['h_violation']:[ 3 14 15  0  0 19  0  2  5 10], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.85727142296435
2023-09-05 11:47:16,581 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0225   |
|    entropy_loss         | 2.15     |
|    policy_loss          | 0.0121   |
|    value_loss           | 0.201    |
| stat/                   |          |
|    constraint_violation | 129      |
|    ep_constraint_vio... | 8        |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.934    |
| stat_eval/              |          |
|    constraint_violation | 2.7      |
|    ep_length            | 150      |
|    ep_return            | 143      |
|    ep_reward            | 0.951    |
|    mse                  | 134      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.67     |
--------------------------------------

Training done.
training step :51, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:19,986 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:21,078 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.573 +/- 7.062
eval_results['h_violation']:[13  6  0 11  0  0  0 19 10  9], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:132.77905672670488
2023-09-05 11:47:21,082 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0576   |
|    entropy_loss         | 2.16     |
|    policy_loss          | -0.00731 |
|    value_loss           | 0.0551   |
| stat/                   |          |
|    constraint_violation | 172      |
|    ep_constraint_vio... | 6        |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
| stat_eval/              |          |
|    constraint_violation | 7.9      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.917    |
|    mse                  | 142      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.632    |
--------------------------------------

Training done.
training step :52, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:24,262 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:25,333 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.653 +/- 6.116
eval_results['h_violation']:[12 10  0  0  8  5  0  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.16674011901338
2023-09-05 11:47:25,337 :
---------------------------------------
| lambda/                 |           |
|    current env steps    | 3e+03     |
|    current updating ... | 1         |
|    hard_lambda          | 0.699     |
|    lambda training step | 8         |
|    policy update step   | 5         |
|    soft_lambda          | 0.0391    |
|    trajectory scale     | 0         |
| loss/                   |           |
|    approx_kl            | 0.0338    |
|    entropy_loss         | 2.16      |
|    policy_loss          | -0.000203 |
|    value_loss           | 0.0324    |
| stat/                   |           |
|    constraint_violation | 157       |
|    ep_constraint_vio... | 4.8       |
|    ep_length            | 150       |
|    ep_return            | 139       |
|    ep_reward            | 0.93      |
| stat_eval/              |           |
|    constraint_violation | 7.4       |
|    ep_length            | 150       |
|    ep_return            | 137       |
|    ep_reward            | 0.911     |
|    mse                  | 138       |
| time/                   |           |
|    progress             | 1         |
|    step                 | 3e+03     |
|    step_time            | 0.609     |
---------------------------------------

Training done.
training step :53, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:28,677 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:29,767 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.456 +/- 4.110
eval_results['h_violation']:[0 0 0 0 0 0 0 5 0 0], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [False]
 [False]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:138.08319807073687
2023-09-05 11:47:29,770 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0276   |
|    entropy_loss         | 2.16     |
|    policy_loss          | 0.00877  |
|    value_loss           | 0.0629   |
| stat/                   |          |
|    constraint_violation | 133      |
|    ep_constraint_vio... | 6.7      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.917    |
| stat_eval/              |          |
|    constraint_violation | 3.8      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.923    |
|    mse                  | 124      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.648    |
--------------------------------------

Training done.
training step :54, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:33,100 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:34,218 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.327 +/- 3.644
eval_results['h_violation']:[ 0 14  7  0 11  0  4  6  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]], eval_score:135.35940014877698
2023-09-05 11:47:34,221 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0515   |
|    entropy_loss         | 2.15     |
|    policy_loss          | 0.000583 |
|    value_loss           | 0.0123   |
| stat/                   |          |
|    constraint_violation | 89       |
|    ep_constraint_vio... | 4.1      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.93     |
| stat_eval/              |          |
|    constraint_violation | 6.8      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.922    |
|    mse                  | 132      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.64     |
--------------------------------------

Training done.
training step :55, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:37,633 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:38,738 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.642 +/- 4.721
eval_results['h_violation']:[ 0  9  3  4  9  0  0  0  0 10], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.15914660788457
2023-09-05 11:47:38,741 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0969   |
|    entropy_loss         | 2.16     |
|    policy_loss          | 0.00631  |
|    value_loss           | 0.0249   |
| stat/                   |          |
|    constraint_violation | 122      |
|    ep_constraint_vio... | 2.6      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.929    |
| stat_eval/              |          |
|    constraint_violation | 7        |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.911    |
|    mse                  | 123      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.672    |
--------------------------------------

Training done.
training step :56, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:42,091 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:43,160 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.759 +/- 5.185
eval_results['h_violation']:[ 0 10  0  8 16  3  0  7 10  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.94782472270515
2023-09-05 11:47:43,164 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0311   |
|    entropy_loss         | 2.16     |
|    policy_loss          | 0.00728  |
|    value_loss           | 0.0322   |
| stat/                   |          |
|    constraint_violation | 76       |
|    ep_constraint_vio... | 5.3      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.924    |
| stat_eval/              |          |
|    constraint_violation | 6.3      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.925    |
|    mse                  | 127      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.628    |
--------------------------------------

Training done.
training step :57, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:46,494 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:47,575 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.736 +/- 3.247
eval_results['h_violation']:[12  0  0  8  0  0  1  0  0 10], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.52986639572035
2023-09-05 11:47:47,579 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0515   |
|    entropy_loss         | 2.16     |
|    policy_loss          | 0.00183  |
|    value_loss           | 0.0236   |
| stat/                   |          |
|    constraint_violation | 99       |
|    ep_constraint_vio... | 4.4      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
| stat_eval/              |          |
|    constraint_violation | 4.5      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
|    mse                  | 127      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.622    |
--------------------------------------

Training done.
training step :58, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:50,851 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:51,949 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.118 +/- 3.143
eval_results['h_violation']:[0 0 0 7 0 0 0 0 0 0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:138.58939222425548
2023-09-05 11:47:51,953 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0683   |
|    entropy_loss         | 2.15     |
|    policy_loss          | 0.0425   |
|    value_loss           | 0.0338   |
| stat/                   |          |
|    constraint_violation | 93       |
|    ep_constraint_vio... | 2.1      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.934    |
| stat_eval/              |          |
|    constraint_violation | 4.5      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
|    mse                  | 112      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.635    |
--------------------------------------

Training done.
training step :59, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:55,343 : Checkpoint | temp/model_latest.pt
2023-09-05 11:47:56,432 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 135.615 +/- 4.949
eval_results['h_violation']:[ 7  8  9  0  8  0 10  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:132.63884173818397
2023-09-05 11:47:56,436 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0514   |
|    entropy_loss         | 2.15     |
|    policy_loss          | -0.00735 |
|    value_loss           | 0.00973  |
| stat/                   |          |
|    constraint_violation | 126      |
|    ep_constraint_vio... | 3.3      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.923    |
| stat_eval/              |          |
|    constraint_violation | 13       |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.904    |
|    mse                  | 136      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.617    |
--------------------------------------

Training done.
training step :60, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:47:59,652 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:00,728 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.125 +/- 3.872
eval_results['h_violation']:[ 0  7 13  0  0  7  0  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.1976847143433
2023-09-05 11:48:00,732 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0996   |
|    entropy_loss         | 2.15     |
|    policy_loss          | 0.0106   |
|    value_loss           | 4.66     |
| stat/                   |          |
|    constraint_violation | 219      |
|    ep_constraint_vio... | 7.9      |
|    ep_length            | 138      |
|    ep_return            | 126      |
|    ep_reward            | 0.89     |
| stat_eval/              |          |
|    constraint_violation | 4.5      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
|    mse                  | 119      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.621    |
--------------------------------------

Training done.
training step :61, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:04,041 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:05,041 : Eval | ep_lengths 138.70 +/- 33.90 | ep_return 126.274 +/- 36.659
eval_results['h_violation']:[18  5  0  8  8 10  6 20  7  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:120.50110294077078
2023-09-05 11:48:05,045 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0592   |
|    entropy_loss         | 2.16     |
|    policy_loss          | -0.0169  |
|    value_loss           | 16.2     |
| stat/                   |          |
|    constraint_violation | 310      |
|    ep_constraint_vio... | 17.2     |
|    ep_length            | 127      |
|    ep_return            | 113      |
|    ep_reward            | 0.847    |
| stat_eval/              |          |
|    constraint_violation | 12.6     |
|    ep_length            | 139      |
|    ep_return            | 126      |
|    ep_reward            | 0.877    |
|    mse                  | 163      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.652    |
--------------------------------------

Training done.
training step :62, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:08,383 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:09,466 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.319 +/- 4.053
eval_results['h_violation']:[0 0 8 0 0 0 8 7 0 0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:136.67190572439506
2023-09-05 11:48:09,470 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0377   |
|    entropy_loss         | 2.16     |
|    policy_loss          | 0.0049   |
|    value_loss           | 0.111    |
| stat/                   |          |
|    constraint_violation | 156      |
|    ep_constraint_vio... | 3.9      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.928    |
| stat_eval/              |          |
|    constraint_violation | 6.3      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.922    |
|    mse                  | 124      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.661    |
--------------------------------------

Training done.
training step :63, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:12,659 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:13,729 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.460 +/- 4.509
eval_results['h_violation']:[11  0  0 11  8  0  0 12  0  8], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.92497428871718
2023-09-05 11:48:13,733 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0602   |
|    entropy_loss         | 2.17     |
|    policy_loss          | 0.0327   |
|    value_loss           | 0.13     |
| stat/                   |          |
|    constraint_violation | 159      |
|    ep_constraint_vio... | 9.5      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.91     |
| stat_eval/              |          |
|    constraint_violation | 11.5     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.923    |
|    mse                  | 145      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.621    |
--------------------------------------

Training done.
training step :64, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:17,043 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:18,129 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.346 +/- 5.311
eval_results['h_violation']:[32 31 32 24 24 40 24 40 24 32], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:118.12162200216136
2023-09-05 11:48:18,134 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0406   |
|    entropy_loss         | 2.17     |
|    policy_loss          | -0.0111  |
|    value_loss           | 2.49     |
| stat/                   |          |
|    constraint_violation | 254      |
|    ep_constraint_vio... | 14.7     |
|    ep_length            | 139      |
|    ep_return            | 126      |
|    ep_reward            | 0.883    |
| stat_eval/              |          |
|    constraint_violation | 7.1      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.929    |
|    mse                  | 145      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.693    |
--------------------------------------

Training done.
training step :65, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:21,582 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:22,674 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.298 +/- 4.583
eval_results['h_violation']:[27 24 29 27 31 24 34 24 34 26], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:118.68152584189124
2023-09-05 11:48:22,678 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0204   |
|    entropy_loss         | 2.17     |
|    policy_loss          | -0.00462 |
|    value_loss           | 0.557    |
| stat/                   |          |
|    constraint_violation | 203      |
|    ep_constraint_vio... | 11.7     |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.916    |
| stat_eval/              |          |
|    constraint_violation | 9.5      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.922    |
|    mse                  | 145      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.692    |
--------------------------------------

Training done.
training step :66, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:26,047 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:27,130 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.774 +/- 2.299
eval_results['h_violation']:[24 10 10 15 15 10 14 14 10 14], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:131.22586375287136
2023-09-05 11:48:27,134 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0402   |
|    entropy_loss         | 2.18     |
|    policy_loss          | -0.00412 |
|    value_loss           | 0.665    |
| stat/                   |          |
|    constraint_violation | 199      |
|    ep_constraint_vio... | 10.8     |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.913    |
| stat_eval/              |          |
|    constraint_violation | 4.5      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.938    |
|    mse                  | 131      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.635    |
--------------------------------------

Training done.
training step :67, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:30,523 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:31,611 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.993 +/- 2.669
eval_results['h_violation']:[ 0  0  0 14  9  0  0  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]], eval_score:138.35326673183607
2023-09-05 11:48:31,615 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0404   |
|    entropy_loss         | 2.18     |
|    policy_loss          | 0.00772  |
|    value_loss           | 0.154    |
| stat/                   |          |
|    constraint_violation | 145      |
|    ep_constraint_vio... | 7        |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.929    |
| stat_eval/              |          |
|    constraint_violation | 3.8      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.933    |
|    mse                  | 117      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.63     |
--------------------------------------

Training done.
training step :68, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:34,964 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:36,017 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.049 +/- 4.962
eval_results['h_violation']:[11  9  0 14  0  0  6  0  1 13], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:133.23456244942383
2023-09-05 11:48:36,021 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0359   |
|    entropy_loss         | 2.19     |
|    policy_loss          | 0.0109   |
|    value_loss           | 0.0849   |
| stat/                   |          |
|    constraint_violation | 104      |
|    ep_constraint_vio... | 2.9      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.926    |
| stat_eval/              |          |
|    constraint_violation | 8.6      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.914    |
|    mse                  | 130      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.648    |
--------------------------------------

Training done.
training step :69, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:39,379 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:40,440 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.032 +/- 4.422
eval_results['h_violation']:[ 0  0  6  0  8  0  5  0 10  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.96478559968196
2023-09-05 11:48:40,443 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0497   |
|    entropy_loss         | 2.19     |
|    policy_loss          | 0.011    |
|    value_loss           | 0.0537   |
| stat/                   |          |
|    constraint_violation | 122      |
|    ep_constraint_vio... | 5.2      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.928    |
| stat_eval/              |          |
|    constraint_violation | 5.8      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.934    |
|    mse                  | 132      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.624    |
--------------------------------------

Training done.
training step :70, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:43,701 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:44,778 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.942 +/- 4.962
eval_results['h_violation']:[ 0 16  0 10  0  0 13  4  9  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.2704949503805
2023-09-05 11:48:44,782 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.021    |
|    entropy_loss         | 2.19     |
|    policy_loss          | -0.0103  |
|    value_loss           | 0.0564   |
| stat/                   |          |
|    constraint_violation | 162      |
|    ep_constraint_vio... | 7.3      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.921    |
| stat_eval/              |          |
|    constraint_violation | 8.3      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.92     |
|    mse                  | 134      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.632    |
--------------------------------------

Training done.
training step :71, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:48,199 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:49,261 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.052 +/- 4.585
eval_results['h_violation']:[ 4  0  0  0  8  0 13  1  9  7], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:133.08027725276983
2023-09-05 11:48:49,265 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0353   |
|    entropy_loss         | 2.21     |
|    policy_loss          | 0.0102   |
|    value_loss           | 0.0626   |
| stat/                   |          |
|    constraint_violation | 137      |
|    ep_constraint_vio... | 10.6     |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.909    |
| stat_eval/              |          |
|    constraint_violation | 13.6     |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.907    |
|    mse                  | 141      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.673    |
--------------------------------------

Training done.
training step :72, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:52,466 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:53,534 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.975 +/- 3.527
eval_results['h_violation']:[ 4  0  0  0 17 19  0  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:136.13869370850367
2023-09-05 11:48:53,537 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0285   |
|    entropy_loss         | 2.22     |
|    policy_loss          | -0.00272 |
|    value_loss           | 0.0336   |
| stat/                   |          |
|    constraint_violation | 129      |
|    ep_constraint_vio... | 8.3      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.915    |
| stat_eval/              |          |
|    constraint_violation | 3.6      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.926    |
|    mse                  | 122      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.612    |
--------------------------------------

Training done.
training step :73, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:48:56,735 : Checkpoint | temp/model_latest.pt
2023-09-05 11:48:57,800 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 135.648 +/- 5.070
eval_results['h_violation']:[ 7  0  0 17  0  0  0 18 10  8], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:131.413567981975
2023-09-05 11:48:57,804 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0179   |
|    entropy_loss         | 2.22     |
|    policy_loss          | 0.0142   |
|    value_loss           | 0.0296   |
| stat/                   |          |
|    constraint_violation | 113      |
|    ep_constraint_vio... | 7.9      |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.9      |
| stat_eval/              |          |
|    constraint_violation | 7.1      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.904    |
|    mse                  | 127      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.655    |
--------------------------------------

Training done.
training step :74, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:01,072 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:02,135 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.213 +/- 1.825
eval_results['h_violation']:[ 0  0  0  3  0 18  0  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:139.70575969230603
2023-09-05 11:49:02,138 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0256   |
|    entropy_loss         | 2.22     |
|    policy_loss          | -0.00965 |
|    value_loss           | 0.0281   |
| stat/                   |          |
|    constraint_violation | 138      |
|    ep_constraint_vio... | 7.4      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.911    |
| stat_eval/              |          |
|    constraint_violation | 0.6      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.941    |
|    mse                  | 121      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.643    |
--------------------------------------

Training done.
training step :75, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:05,410 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:06,526 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.265 +/- 6.470
eval_results['h_violation']:[ 0 11 12  0  0  0 12  0 10  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.07988763488046
2023-09-05 11:49:06,530 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.044    |
|    entropy_loss         | 2.22     |
|    policy_loss          | 0.0148   |
|    value_loss           | 0.385    |
| stat/                   |          |
|    constraint_violation | 105      |
|    ep_constraint_vio... | 5.5      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
| stat_eval/              |          |
|    constraint_violation | 8.8      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.915    |
|    mse                  | 137      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.651    |
--------------------------------------

Training done.
training step :76, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:10,138 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:11,221 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.587 +/- 4.233
eval_results['h_violation']:[ 8 18  3  9  0 19  0  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.5660649595969
2023-09-05 11:49:11,225 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0449   |
|    entropy_loss         | 2.22     |
|    policy_loss          | -0.00516 |
|    value_loss           | 0.0212   |
| stat/                   |          |
|    constraint_violation | 114      |
|    ep_constraint_vio... | 4.6      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
| stat_eval/              |          |
|    constraint_violation | 6.3      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.924    |
|    mse                  | 131      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.695    |
--------------------------------------

Training done.
training step :77, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:14,748 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:15,839 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.410 +/- 4.222
eval_results['h_violation']:[0 0 0 5 0 6 0 0 8 8], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]], eval_score:136.49432260558544
2023-09-05 11:49:15,845 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0343   |
|    entropy_loss         | 2.22     |
|    policy_loss          | -0.00193 |
|    value_loss           | 0.0203   |
| stat/                   |          |
|    constraint_violation | 84       |
|    ep_constraint_vio... | 4.8      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.931    |
| stat_eval/              |          |
|    constraint_violation | 4.3      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.923    |
|    mse                  | 118      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.695    |
--------------------------------------

Training done.
training step :78, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:19,233 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:20,292 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.983 +/- 4.194
eval_results['h_violation']:[0 0 0 0 0 0 7 0 0 7], (eval_results['s_violation']>0):[[ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]], eval_score:137.97644718338415
2023-09-05 11:49:20,296 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0624   |
|    entropy_loss         | 2.23     |
|    policy_loss          | 0.0145   |
|    value_loss           | 0.0267   |
| stat/                   |          |
|    constraint_violation | 62       |
|    ep_constraint_vio... | 3.4      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.935    |
| stat_eval/              |          |
|    constraint_violation | 4.2      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
|    mse                  | 118      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.641    |
--------------------------------------

Training done.
training step :79, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:23,463 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:24,510 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 135.197 +/- 5.137
eval_results['h_violation']:[10 13  5  9  0  0  0 13  5  0], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [ True]
 [ True]], eval_score:131.32379924658392
2023-09-05 11:49:24,513 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0639   |
|    entropy_loss         | 2.23     |
|    policy_loss          | 0.0111   |
|    value_loss           | 0.0114   |
| stat/                   |          |
|    constraint_violation | 180      |
|    ep_constraint_vio... | 8.4      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.904    |
| stat_eval/              |          |
|    constraint_violation | 11       |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.901    |
|    mse                  | 130      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.621    |
--------------------------------------

Training done.
training step :80, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:27,717 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:28,804 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 135.270 +/- 4.532
eval_results['h_violation']:[ 8  0  4  4  6  0  0 11  5  6], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:132.1580970969805
2023-09-05 11:49:28,808 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0259   |
|    entropy_loss         | 2.23     |
|    policy_loss          | -0.00197 |
|    value_loss           | 0.0132   |
| stat/                   |          |
|    constraint_violation | 95       |
|    ep_constraint_vio... | 5.2      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.922    |
| stat_eval/              |          |
|    constraint_violation | 11.3     |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.902    |
|    mse                  | 128      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.623    |
--------------------------------------

Training done.
training step :81, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:32,274 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:33,426 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.058 +/- 5.025
eval_results['h_violation']:[ 2  0  0  0  0  0  0 11  8 12], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]], eval_score:135.71970450708722
2023-09-05 11:49:33,431 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0506   |
|    entropy_loss         | 2.23     |
|    policy_loss          | 0.0156   |
|    value_loss           | 0.0256   |
| stat/                   |          |
|    constraint_violation | 92       |
|    ep_constraint_vio... | 6        |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.918    |
| stat_eval/              |          |
|    constraint_violation | 5.9      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.92     |
|    mse                  | 121      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.605    |
--------------------------------------

Training done.
training step :82, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:36,753 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:37,800 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.677 +/- 4.781
eval_results['h_violation']:[ 1 10  8  0  0 10  0 14  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:135.6353786395698
2023-09-05 11:49:37,803 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0424   |
|    entropy_loss         | 2.23     |
|    policy_loss          | -0.0171  |
|    value_loss           | 0.0232   |
| stat/                   |          |
|    constraint_violation | 102      |
|    ep_constraint_vio... | 6.9      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.924    |
| stat_eval/              |          |
|    constraint_violation | 7.4      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.925    |
|    mse                  | 128      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.613    |
--------------------------------------

Training done.
training step :83, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:41,049 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:42,105 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 142.510 +/- 0.902
eval_results['h_violation']:[ 0 13  0 12  9 16  0  0 16  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.86046145924195
2023-09-05 11:49:42,108 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0228   |
|    entropy_loss         | 2.23     |
|    policy_loss          | -0.00361 |
|    value_loss           | 0.0272   |
| stat/                   |          |
|    constraint_violation | 145      |
|    ep_constraint_vio... | 5.9      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.931    |
| stat_eval/              |          |
|    constraint_violation | 0.5      |
|    ep_length            | 150      |
|    ep_return            | 143      |
|    ep_reward            | 0.95     |
|    mse                  | 119      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.639    |
--------------------------------------

Training done.
training step :84, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:45,385 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:46,460 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.665 +/- 2.541
eval_results['h_violation']:[ 8 16  0  0  1  0  0 15 14  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.85010681656183
2023-09-05 11:49:46,465 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.031    |
|    entropy_loss         | 2.24     |
|    policy_loss          | 0.000535 |
|    value_loss           | 0.0154   |
| stat/                   |          |
|    constraint_violation | 170      |
|    ep_constraint_vio... | 6.5      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.933    |
| stat_eval/              |          |
|    constraint_violation | 2.8      |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.944    |
|    mse                  | 124      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.649    |
--------------------------------------

Training done.
training step :85, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:49,678 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:50,753 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 142.284 +/- 1.850
eval_results['h_violation']:[ 0  0 14  0  0  9  0  0  0  0], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:140.64101655638194
2023-09-05 11:49:50,756 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.092    |
|    entropy_loss         | 2.24     |
|    policy_loss          | 0.008    |
|    value_loss           | 0.0177   |
| stat/                   |          |
|    constraint_violation | 139      |
|    ep_constraint_vio... | 6.9      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.928    |
| stat_eval/              |          |
|    constraint_violation | 1        |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.949    |
|    mse                  | 115      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.594    |
--------------------------------------

Training done.
training step :86, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:54,065 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:55,166 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.471 +/- 3.799
eval_results['h_violation']:[15  0  1  0  6 16  0  0  8  6], (eval_results['s_violation']>0):[[ True]
 [False]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]], eval_score:134.81170132863966
2023-09-05 11:49:55,170 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0664   |
|    entropy_loss         | 2.24     |
|    policy_loss          | 0.0422   |
|    value_loss           | 0.0113   |
| stat/                   |          |
|    constraint_violation | 115      |
|    ep_constraint_vio... | 5.4      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.934    |
| stat_eval/              |          |
|    constraint_violation | 5.6      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.923    |
|    mse                  | 118      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.617    |
--------------------------------------

Training done.
training step :87, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:49:58,795 : Checkpoint | temp/model_latest.pt
2023-09-05 11:49:59,933 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.668 +/- 4.899
eval_results['h_violation']:[ 8 11  8 10  6  0  0  5 12  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]], eval_score:133.44134036361731
2023-09-05 11:49:59,937 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0306   |
|    entropy_loss         | 2.25     |
|    policy_loss          | 0.00134  |
|    value_loss           | 0.0208   |
| stat/                   |          |
|    constraint_violation | 154      |
|    ep_constraint_vio... | 9        |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.919    |
| stat_eval/              |          |
|    constraint_violation | 9.5      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.918    |
|    mse                  | 127      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.726    |
--------------------------------------

Training done.
training step :88, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:03,476 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:04,578 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.175 +/- 4.845
eval_results['h_violation']:[ 0 10 16  0  9  0  0  0  0  0], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [ True]
 [ True]
 [ True]], eval_score:137.70079708010974
2023-09-05 11:50:04,582 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0528   |
|    entropy_loss         | 2.25     |
|    policy_loss          | 0.0195   |
|    value_loss           | 0.00886  |
| stat/                   |          |
|    constraint_violation | 121      |
|    ep_constraint_vio... | 7.3      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.923    |
| stat_eval/              |          |
|    constraint_violation | 5.5      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.935    |
|    mse                  | 126      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.62     |
--------------------------------------

Training done.
training step :89, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:07,815 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:08,872 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.086 +/- 4.264
eval_results['h_violation']:[ 0  0 13  0  7 13 12  0  0  9], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]], eval_score:136.27865870602548
2023-09-05 11:50:08,876 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.035    |
|    entropy_loss         | 2.25     |
|    policy_loss          | 0.00357  |
|    value_loss           | 0.0236   |
| stat/                   |          |
|    constraint_violation | 160      |
|    ep_constraint_vio... | 10       |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.926    |
| stat_eval/              |          |
|    constraint_violation | 5.7      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.934    |
|    mse                  | 125      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.614    |
--------------------------------------

Training done.
training step :90, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:12,093 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:13,155 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.752 +/- 2.302
eval_results['h_violation']:[0 5 8 0 0 0 0 0 0 0], (eval_results['s_violation']>0):[[ True]
 [False]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]], eval_score:138.8154075350968
2023-09-05 11:50:13,159 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0335   |
|    entropy_loss         | 2.26     |
|    policy_loss          | 0.00838  |
|    value_loss           | 0.00555  |
| stat/                   |          |
|    constraint_violation | 124      |
|    ep_constraint_vio... | 6.4      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
| stat_eval/              |          |
|    constraint_violation | 5.1      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
|    mse                  | 120      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.624    |
--------------------------------------

Training done.
training step :91, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:16,491 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:17,652 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.018 +/- 3.495
eval_results['h_violation']:[0 0 0 5 3 0 0 0 4 8], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [False]
 [False]
 [False]
 [ True]
 [ True]
 [False]
 [ True]], eval_score:135.59574431706187
2023-09-05 11:50:17,656 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0643   |
|    entropy_loss         | 2.27     |
|    policy_loss          | 0.0244   |
|    value_loss           | 0.0134   |
| stat/                   |          |
|    constraint_violation | 197      |
|    ep_constraint_vio... | 11.9     |
|    ep_length            | 150      |
|    ep_return            | 135      |
|    ep_reward            | 0.903    |
| stat_eval/              |          |
|    constraint_violation | 5        |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.913    |
|    mse                  | 105      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.636    |
--------------------------------------

Training done.
training step :92, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:21,164 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:22,311 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.069 +/- 4.438
eval_results['h_violation']:[ 0 11  0  0  0  9  0  0  0  0], (eval_results['s_violation']>0):[[False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]], eval_score:136.64729013938063
2023-09-05 11:50:22,316 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0564   |
|    entropy_loss         | 2.26     |
|    policy_loss          | -0.00411 |
|    value_loss           | 0.0245   |
| stat/                   |          |
|    constraint_violation | 173      |
|    ep_constraint_vio... | 10.3     |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.915    |
| stat_eval/              |          |
|    constraint_violation | 8.8      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.92     |
|    mse                  | 123      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.82     |
--------------------------------------

Training done.
training step :93, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:25,779 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:26,886 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.607 +/- 4.063
eval_results['h_violation']:[ 0 11  9  0  0  0  0  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [ True]
 [ True]
 [ True]], eval_score:137.17757222980194
2023-09-05 11:50:26,890 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.067    |
|    entropy_loss         | 2.27     |
|    policy_loss          | 0.00186  |
|    value_loss           | 0.128    |
| stat/                   |          |
|    constraint_violation | 206      |
|    ep_constraint_vio... | 6.8      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.925    |
| stat_eval/              |          |
|    constraint_violation | 10.5     |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.924    |
|    mse                  | 133      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.696    |
--------------------------------------

Training done.
training step :94, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:30,285 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:31,353 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.191 +/- 3.645
eval_results['h_violation']:[ 0  0  9 11  0  0  0 12  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]], eval_score:135.9219296128918
2023-09-05 11:50:31,356 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0642   |
|    entropy_loss         | 2.27     |
|    policy_loss          | 0.00398  |
|    value_loss           | 0.0121   |
| stat/                   |          |
|    constraint_violation | 184      |
|    ep_constraint_vio... | 8.6      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.926    |
| stat_eval/              |          |
|    constraint_violation | 10.4     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.921    |
|    mse                  | 132      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.649    |
--------------------------------------

Training done.
training step :95, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:34,768 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:35,888 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.892 +/- 4.270
eval_results['h_violation']:[11  8 10  0  0  0 12  0  0  5], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]], eval_score:134.6447426062949
2023-09-05 11:50:35,892 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0382   |
|    entropy_loss         | 2.27     |
|    policy_loss          | 0.0104   |
|    value_loss           | 0.021    |
| stat/                   |          |
|    constraint_violation | 171      |
|    ep_constraint_vio... | 6.5      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.937    |
| stat_eval/              |          |
|    constraint_violation | 11.4     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.919    |
|    mse                  | 136      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.653    |
--------------------------------------

Training done.
training step :96, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:39,505 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:40,505 : Eval | ep_lengths 138.90 +/- 33.30 | ep_return 125.910 +/- 36.097
eval_results['h_violation']:[25  5  0  0  0 13 14  0  6  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:121.46949885382601
2023-09-05 11:50:40,509 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.126    |
|    entropy_loss         | 2.27     |
|    policy_loss          | 0.0425   |
|    value_loss           | 0.00509  |
| stat/                   |          |
|    constraint_violation | 201      |
|    ep_constraint_vio... | 10.8     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.917    |
| stat_eval/              |          |
|    constraint_violation | 13.8     |
|    ep_length            | 139      |
|    ep_return            | 126      |
|    ep_reward            | 0.874    |
|    mse                  | 166      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.633    |
--------------------------------------

Training done.
training step :97, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:44,013 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:44,956 : Eval | ep_lengths 125.20 +/- 49.60 | ep_return 117.102 +/- 50.928
eval_results['h_violation']:[ 4  0 12  2  0  0  6 16 13  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:113.35758238169437
2023-09-05 11:50:44,960 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0182   |
|    entropy_loss         | 2.27     |
|    policy_loss          | 0.0039   |
|    value_loss           | 4.38     |
| stat/                   |          |
|    constraint_violation | 220      |
|    ep_constraint_vio... | 8.4      |
|    ep_length            | 125      |
|    ep_return            | 115      |
|    ep_reward            | 0.836    |
| stat_eval/              |          |
|    constraint_violation | 6.5      |
|    ep_length            | 125      |
|    ep_return            | 117      |
|    ep_reward            | 0.878    |
|    mse                  | 133      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.684    |
--------------------------------------

Training done.
training step :98, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:49,126 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:50,336 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.337 +/- 4.040
eval_results['h_violation']:[ 0  2  4  6  0  0  0 13  2  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:136.41041739326187
2023-09-05 11:50:50,339 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.039    |
|    entropy_loss         | 2.27     |
|    policy_loss          | 0.0043   |
|    value_loss           | 5.33     |
| stat/                   |          |
|    constraint_violation | 191      |
|    ep_constraint_vio... | 10.7     |
|    ep_length            | 127      |
|    ep_return            | 114      |
|    ep_reward            | 0.826    |
| stat_eval/              |          |
|    constraint_violation | 9        |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.922    |
|    mse                  | 125      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.846    |
--------------------------------------

Training done.
training step :99, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:53,884 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:54,829 : Eval | ep_lengths 125.50 +/- 49.00 | ep_return 117.938 +/- 51.296
eval_results['h_violation']:[ 7  7  7 18 15 19 14  7  7 11], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:110.06774272168349
2023-09-05 11:50:54,832 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0142   |
|    entropy_loss         | 2.28     |
|    policy_loss          | -0.00796 |
|    value_loss           | 2.3      |
| stat/                   |          |
|    constraint_violation | 291      |
|    ep_constraint_vio... | 15.2     |
|    ep_length            | 114      |
|    ep_return            | 103      |
|    ep_reward            | 0.832    |
| stat_eval/              |          |
|    constraint_violation | 8.6      |
|    ep_length            | 126      |
|    ep_return            | 118      |
|    ep_reward            | 0.878    |
|    mse                  | 148      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.748    |
--------------------------------------

Training done.
training step :100, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:50:58,403 : Checkpoint | temp/model_latest.pt
2023-09-05 11:50:59,430 : Eval | ep_lengths 139.40 +/- 31.80 | ep_return 125.004 +/- 35.627
eval_results['h_violation']:[13  3  3 10 19  3  3 13 12 26], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:117.62354439035475
2023-09-05 11:50:59,434 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0333   |
|    entropy_loss         | 2.28     |
|    policy_loss          | 0.0017   |
|    value_loss           | 0.221    |
| stat/                   |          |
|    constraint_violation | 241      |
|    ep_constraint_vio... | 10.5     |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.935    |
| stat_eval/              |          |
|    constraint_violation | 15.4     |
|    ep_length            | 139      |
|    ep_return            | 125      |
|    ep_reward            | 0.864    |
|    mse                  | 166      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.69     |
--------------------------------------

Training done.
training step :101, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:02,989 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:04,137 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.301 +/- 4.909
eval_results['h_violation']:[ 0  7  0  0  9 14  1  0  0  8], (eval_results['s_violation']>0):[[ True]
 [False]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [ True]], eval_score:136.55052027867058
2023-09-05 11:51:04,141 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0248   |
|    entropy_loss         | 2.28     |
|    policy_loss          | 0.00064  |
|    value_loss           | 0.179    |
| stat/                   |          |
|    constraint_violation | 184      |
|    ep_constraint_vio... | 7.1      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.925    |
| stat_eval/              |          |
|    constraint_violation | 5.7      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.929    |
|    mse                  | 122      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.691    |
--------------------------------------

Training done.
training step :102, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:07,678 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:08,785 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.817 +/- 4.393
eval_results['h_violation']:[ 0  0  0  8  0 11 15  0  0  0], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]], eval_score:136.41647812052958
2023-09-05 11:51:08,789 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0277   |
|    entropy_loss         | 2.28     |
|    policy_loss          | 0.00931  |
|    value_loss           | 0.0773   |
| stat/                   |          |
|    constraint_violation | 110      |
|    ep_constraint_vio... | 5.2      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.93     |
| stat_eval/              |          |
|    constraint_violation | 5.7      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.925    |
|    mse                  | 116      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.671    |
--------------------------------------

Training done.
training step :103, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:12,317 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:13,402 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.483 +/- 2.255
eval_results['h_violation']:[ 0 15 10  0  0  0  0 17  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:136.50717172184298
2023-09-05 11:51:13,406 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0331   |
|    entropy_loss         | 2.29     |
|    policy_loss          | 0.0102   |
|    value_loss           | 0.0578   |
| stat/                   |          |
|    constraint_violation | 132      |
|    ep_constraint_vio... | 8.6      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.91     |
| stat_eval/              |          |
|    constraint_violation | 3.5      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.93     |
|    mse                  | 112      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.699    |
--------------------------------------

Training done.
training step :104, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:16,966 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:18,080 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.210 +/- 5.229
eval_results['h_violation']:[11 10  5  0  0  0 16  0  3  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [False]], eval_score:134.03256086921584
2023-09-05 11:51:18,085 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0918   |
|    entropy_loss         | 2.29     |
|    policy_loss          | 0.0181   |
|    value_loss           | 0.472    |
| stat/                   |          |
|    constraint_violation | 176      |
|    ep_constraint_vio... | 11.8     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.923    |
| stat_eval/              |          |
|    constraint_violation | 9.3      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.915    |
|    mse                  | 125      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.671    |
--------------------------------------

Training done.
training step :105, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:21,527 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:22,627 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.791 +/- 5.189
eval_results['h_violation']:[ 0  9  9  0  0  4  6 15  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]], eval_score:135.74921062910846
2023-09-05 11:51:22,631 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0289   |
|    entropy_loss         | 2.29     |
|    policy_loss          | -0.00137 |
|    value_loss           | 0.0226   |
| stat/                   |          |
|    constraint_violation | 84       |
|    ep_constraint_vio... | 0.2      |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.947    |
| stat_eval/              |          |
|    constraint_violation | 6.3      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.925    |
|    mse                  | 119      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.677    |
--------------------------------------

Training done.
training step :106, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:26,212 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:27,333 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.058 +/- 5.113
eval_results['h_violation']:[ 0  0  0  0  0 11  4  6  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.5547858241855
2023-09-05 11:51:27,337 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0151   |
|    entropy_loss         | 2.3      |
|    policy_loss          | -0.00148 |
|    value_loss           | 0.0113   |
| stat/                   |          |
|    constraint_violation | 78       |
|    ep_constraint_vio... | 1.7      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.934    |
| stat_eval/              |          |
|    constraint_violation | 5.7      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
|    mse                  | 117      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.71     |
--------------------------------------

Training done.
training step :107, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:30,878 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:31,979 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.593 +/- 4.906
eval_results['h_violation']:[ 0  0  0  0 10  3  0  0  0  1], (eval_results['s_violation']>0):[[ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.578645496707
2023-09-05 11:51:31,983 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0449   |
|    entropy_loss         | 2.29     |
|    policy_loss          | 0.0182   |
|    value_loss           | 0.0366   |
| stat/                   |          |
|    constraint_violation | 160      |
|    ep_constraint_vio... | 7.6      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
| stat_eval/              |          |
|    constraint_violation | 6.8      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.924    |
|    mse                  | 125      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.675    |
--------------------------------------

Training done.
training step :108, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:35,456 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:36,552 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.585 +/- 4.474
eval_results['h_violation']:[ 9  0  0  0  0  4  0 14 11  5], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:136.53966132831178
2023-09-05 11:51:36,556 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0634   |
|    entropy_loss         | 2.3      |
|    policy_loss          | 0.0267   |
|    value_loss           | 0.0255   |
| stat/                   |          |
|    constraint_violation | 129      |
|    ep_constraint_vio... | 8.3      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.926    |
| stat_eval/              |          |
|    constraint_violation | 5.6      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.931    |
|    mse                  | 124      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.726    |
--------------------------------------

Training done.
training step :109, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:40,137 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:41,223 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.325 +/- 5.678
eval_results['h_violation']:[ 0  0  8 15  0  0  8  0 15 11], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:133.30034411493702
2023-09-05 11:51:41,228 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0385   |
|    entropy_loss         | 2.31     |
|    policy_loss          | -0.0127  |
|    value_loss           | 0.234    |
| stat/                   |          |
|    constraint_violation | 119      |
|    ep_constraint_vio... | 3.8      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.93     |
| stat_eval/              |          |
|    constraint_violation | 7.1      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.915    |
|    mse                  | 123      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.673    |
--------------------------------------

Training done.
training step :110, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:44,829 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:45,964 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.858 +/- 5.751
eval_results['h_violation']:[18  5  0  7  7  0  0  0  9  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.60277117509492
2023-09-05 11:51:45,968 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0297   |
|    entropy_loss         | 2.31     |
|    policy_loss          | 0.0015   |
|    value_loss           | 0.21     |
| stat/                   |          |
|    constraint_violation | 195      |
|    ep_constraint_vio... | 14.3     |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.908    |
| stat_eval/              |          |
|    constraint_violation | 5.1      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.919    |
|    mse                  | 120      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.692    |
--------------------------------------

Training done.
training step :111, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:49,517 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:50,591 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 135.633 +/- 5.490
eval_results['h_violation']:[ 1  7 12  0  0  0  0  0  4  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]], eval_score:133.9201725497266
2023-09-05 11:51:50,595 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0572   |
|    entropy_loss         | 2.31     |
|    policy_loss          | 0.0291   |
|    value_loss           | 0.0225   |
| stat/                   |          |
|    constraint_violation | 82       |
|    ep_constraint_vio... | 4.9      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.92     |
| stat_eval/              |          |
|    constraint_violation | 6.7      |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.904    |
|    mse                  | 113      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.658    |
--------------------------------------

Training done.
training step :112, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:54,014 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:55,112 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.220 +/- 4.027
eval_results['h_violation']:[ 0 18  0  0 10  0  0  0  0  6], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.8035538575091
2023-09-05 11:51:55,116 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0494   |
|    entropy_loss         | 2.31     |
|    policy_loss          | -0.00238 |
|    value_loss           | 0.478    |
| stat/                   |          |
|    constraint_violation | 162      |
|    ep_constraint_vio... | 10.4     |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.907    |
| stat_eval/              |          |
|    constraint_violation | 4.6      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.935    |
|    mse                  | 121      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.701    |
--------------------------------------

Training done.
training step :113, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:51:58,591 : Checkpoint | temp/model_latest.pt
2023-09-05 11:51:59,664 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.690 +/- 3.575
eval_results['h_violation']:[0 6 0 9 0 0 0 3 0 0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:138.39213010945022
2023-09-05 11:51:59,668 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0186   |
|    entropy_loss         | 2.31     |
|    policy_loss          | 0.000794 |
|    value_loss           | 0.0232   |
| stat/                   |          |
|    constraint_violation | 130      |
|    ep_constraint_vio... | 7.9      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.916    |
| stat_eval/              |          |
|    constraint_violation | 4.5      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.931    |
|    mse                  | 118      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.683    |
--------------------------------------

Training done.
training step :114, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:03,091 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:04,180 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.881 +/- 4.217
eval_results['h_violation']:[ 0  6  0  7 16  5  0  5 12  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.2760857287689
2023-09-05 11:52:04,185 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0956   |
|    entropy_loss         | 2.32     |
|    policy_loss          | 0.0245   |
|    value_loss           | 0.0198   |
| stat/                   |          |
|    constraint_violation | 80       |
|    ep_constraint_vio... | 4.8      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.928    |
| stat_eval/              |          |
|    constraint_violation | 10.1     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.919    |
|    mse                  | 129      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.652    |
--------------------------------------

Training done.
training step :115, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:07,780 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:08,927 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.665 +/- 4.620
eval_results['h_violation']:[ 6  0  8  0  0  0 10 11  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:135.17844147139428
2023-09-05 11:52:08,931 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0382   |
|    entropy_loss         | 2.33     |
|    policy_loss          | 0.00943  |
|    value_loss           | 0.0321   |
| stat/                   |          |
|    constraint_violation | 139      |
|    ep_constraint_vio... | 5.6      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.939    |
| stat_eval/              |          |
|    constraint_violation | 10.2     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.918    |
|    mse                  | 128      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.686    |
--------------------------------------

Training done.
training step :116, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:12,176 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:13,244 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.264 +/- 5.228
eval_results['h_violation']:[0 0 0 8 6 0 0 0 9 0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.61715979185956
2023-09-05 11:52:13,247 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0248   |
|    entropy_loss         | 2.32     |
|    policy_loss          | -0.00158 |
|    value_loss           | 0.155    |
| stat/                   |          |
|    constraint_violation | 115      |
|    ep_constraint_vio... | 3.8      |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.944    |
| stat_eval/              |          |
|    constraint_violation | 8        |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.928    |
|    mse                  | 134      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.649    |
--------------------------------------

Training done.
training step :117, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:16,757 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:17,862 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.721 +/- 2.879
eval_results['h_violation']:[ 0  0  0  0  0  0  0  0 17  2], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:140.35303068116252
2023-09-05 11:52:17,865 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0493   |
|    entropy_loss         | 2.32     |
|    policy_loss          | 0.015    |
|    value_loss           | 0.0256   |
| stat/                   |          |
|    constraint_violation | 110      |
|    ep_constraint_vio... | 6.1      |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.944    |
| stat_eval/              |          |
|    constraint_violation | 4.1      |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.945    |
|    mse                  | 131      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.674    |
--------------------------------------

Training done.
training step :118, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:21,125 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:22,205 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.551 +/- 3.108
eval_results['h_violation']:[15  0  0 14  5  0  0  0 17 15], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:135.89762497722472
2023-09-05 11:52:22,209 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0271   |
|    entropy_loss         | 2.32     |
|    policy_loss          | -0.0138  |
|    value_loss           | 12.7     |
| stat/                   |          |
|    constraint_violation | 226      |
|    ep_constraint_vio... | 10.9     |
|    ep_length            | 138      |
|    ep_return            | 126      |
|    ep_reward            | 0.881    |
| stat_eval/              |          |
|    constraint_violation | 5.1      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.937    |
|    mse                  | 129      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.634    |
--------------------------------------

Training done.
training step :119, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:25,432 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:26,498 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.617 +/- 5.444
eval_results['h_violation']:[11 16  0  7  0 10  0  0  0  8], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:133.9425200578218
2023-09-05 11:52:26,502 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0529   |
|    entropy_loss         | 2.32     |
|    policy_loss          | 0.023    |
|    value_loss           | 0.031    |
| stat/                   |          |
|    constraint_violation | 214      |
|    ep_constraint_vio... | 11.3     |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.913    |
| stat_eval/              |          |
|    constraint_violation | 10.4     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.917    |
|    mse                  | 131      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.598    |
--------------------------------------

Training done.
training step :120, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:29,796 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:30,876 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.732 +/- 4.391
eval_results['h_violation']:[ 9  0  2  0  6  0  5  0 15  9], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:136.47612275451417
2023-09-05 11:52:30,880 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0283   |
|    entropy_loss         | 2.32     |
|    policy_loss          | 0.0136   |
|    value_loss           | 0.0395   |
| stat/                   |          |
|    constraint_violation | 226      |
|    ep_constraint_vio... | 11.9     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.919    |
| stat_eval/              |          |
|    constraint_violation | 9.1      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
|    mse                  | 133      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.655    |
--------------------------------------

Training done.
training step :121, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:34,038 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:35,093 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.473 +/- 4.190
eval_results['h_violation']:[ 7  4 20  4  4 10  9 12 13  4], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.35119855889775
2023-09-05 11:52:35,096 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0603   |
|    entropy_loss         | 2.32     |
|    policy_loss          | 0.0158   |
|    value_loss           | 0.201    |
| stat/                   |          |
|    constraint_violation | 148      |
|    ep_constraint_vio... | 7.6      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.936    |
| stat_eval/              |          |
|    constraint_violation | 8        |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.936    |
|    mse                  | 139      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.607    |
--------------------------------------

Training done.
training step :122, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:38,410 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:39,499 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 142.965 +/- 1.619
eval_results['h_violation']:[12  0  7  0  0  4 11 16  4 16], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]], eval_score:138.04372791180734
2023-09-05 11:52:39,502 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0261   |
|    entropy_loss         | 2.33     |
|    policy_loss          | 0.00633  |
|    value_loss           | 0.695    |
| stat/                   |          |
|    constraint_violation | 145      |
|    ep_constraint_vio... | 6.1      |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.946    |
| stat_eval/              |          |
|    constraint_violation | 3        |
|    ep_length            | 150      |
|    ep_return            | 143      |
|    ep_reward            | 0.953    |
|    mse                  | 129      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.637    |
--------------------------------------

Training done.
training step :123, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:42,751 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:43,817 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.692 +/- 4.343
eval_results['h_violation']:[ 5  8  8  5  3  7  0 11  1  4], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.01739918580887
2023-09-05 11:52:43,821 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0205   |
|    entropy_loss         | 2.34     |
|    policy_loss          | -0.00599 |
|    value_loss           | 0.23     |
| stat/                   |          |
|    constraint_violation | 185      |
|    ep_constraint_vio... | 10.5     |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
| stat_eval/              |          |
|    constraint_violation | 7.6      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.938    |
|    mse                  | 141      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.631    |
--------------------------------------

Training done.
training step :124, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:46,937 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:48,045 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.200 +/- 3.907
eval_results['h_violation']:[10 10 11 19 14 32 16 10 14 14], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:129.67262569306206
2023-09-05 11:52:48,049 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.107    |
|    entropy_loss         | 2.33     |
|    policy_loss          | 0.0681   |
|    value_loss           | 0.0543   |
| stat/                   |          |
|    constraint_violation | 171      |
|    ep_constraint_vio... | 9.6      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.931    |
| stat_eval/              |          |
|    constraint_violation | 10.1     |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.935    |
|    mse                  | 149      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.604    |
--------------------------------------

Training done.
training step :125, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:51,290 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:52,361 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.471 +/- 3.648
eval_results['h_violation']:[24 22 27 25 18 39 37 23 24 26], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:122.90264539037858
2023-09-05 11:52:52,364 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0972   |
|    entropy_loss         | 2.33     |
|    policy_loss          | 0.0587   |
|    value_loss           | 0.274    |
| stat/                   |          |
|    constraint_violation | 137      |
|    ep_constraint_vio... | 6.1      |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.945    |
| stat_eval/              |          |
|    constraint_violation | 10.6     |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.943    |
|    mse                  | 157      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.589    |
--------------------------------------

Training done.
training step :126, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:55,637 : Checkpoint | temp/model_latest.pt
2023-09-05 11:52:56,699 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 142.591 +/- 3.406
eval_results['h_violation']:[15 18 19 25 19 18 23 19 19 18], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:129.0570875553498
2023-09-05 11:52:56,703 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0336   |
|    entropy_loss         | 2.33     |
|    policy_loss          | 0.00319  |
|    value_loss           | 0.134    |
| stat/                   |          |
|    constraint_violation | 267      |
|    ep_constraint_vio... | 18.6     |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.931    |
| stat_eval/              |          |
|    constraint_violation | 10.9     |
|    ep_length            | 150      |
|    ep_return            | 143      |
|    ep_reward            | 0.951    |
|    mse                  | 151      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.636    |
--------------------------------------

Training done.
training step :127, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:52:59,911 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:00,980 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.567 +/- 3.194
eval_results['h_violation']:[14 19 12 15 15 13 18 14 17 15], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:128.90056727112136
2023-09-05 11:53:00,984 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0476   |
|    entropy_loss         | 2.33     |
|    policy_loss          | 0.0101   |
|    value_loss           | 0.354    |
| stat/                   |          |
|    constraint_violation | 312      |
|    ep_constraint_vio... | 11.5     |
|    ep_length            | 150      |
|    ep_return            | 142      |
|    ep_reward            | 0.949    |
| stat_eval/              |          |
|    constraint_violation | 15.1     |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.93     |
|    mse                  | 163      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.609    |
--------------------------------------

Training done.
training step :128, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:04,258 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:05,315 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.708 +/- 4.492
eval_results['h_violation']:[ 9 15 16 11  8  0  8  5  2  6], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.0756307334878
2023-09-05 11:53:05,319 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0412   |
|    entropy_loss         | 2.34     |
|    policy_loss          | 0.012    |
|    value_loss           | 0.366    |
| stat/                   |          |
|    constraint_violation | 289      |
|    ep_constraint_vio... | 15.7     |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
| stat_eval/              |          |
|    constraint_violation | 9.2      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.931    |
|    mse                  | 150      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.621    |
--------------------------------------

Training done.
training step :129, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:08,736 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:09,825 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.583 +/- 3.827
eval_results['h_violation']:[17 17  0  8  4  3  6  5  8  3], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:133.5793186050972
2023-09-05 11:53:09,829 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0383   |
|    entropy_loss         | 2.34     |
|    policy_loss          | -0.0105  |
|    value_loss           | 0.0343   |
| stat/                   |          |
|    constraint_violation | 220      |
|    ep_constraint_vio... | 12.4     |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.928    |
| stat_eval/              |          |
|    constraint_violation | 15.7     |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.924    |
|    mse                  | 156      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.638    |
--------------------------------------

Training done.
training step :130, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:13,030 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:14,107 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.953 +/- 3.752
eval_results['h_violation']:[ 7  6  0 11  0  4  6  0  7  2], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:136.90695572063652
2023-09-05 11:53:14,111 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0297   |
|    entropy_loss         | 2.34     |
|    policy_loss          | 0.00396  |
|    value_loss           | 0.0203   |
| stat/                   |          |
|    constraint_violation | 265      |
|    ep_constraint_vio... | 13.4     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.921    |
| stat_eval/              |          |
|    constraint_violation | 9.3      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.933    |
|    mse                  | 145      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.622    |
--------------------------------------

Training done.
training step :131, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:17,440 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:18,524 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.954 +/- 4.269
eval_results['h_violation']:[ 0  7  0  8 12  5  6  9  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:134.62889595623955
2023-09-05 11:53:18,528 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0349   |
|    entropy_loss         | 2.36     |
|    policy_loss          | 0.00493  |
|    value_loss           | 0.1      |
| stat/                   |          |
|    constraint_violation | 181      |
|    ep_constraint_vio... | 7.1      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.943    |
| stat_eval/              |          |
|    constraint_violation | 11       |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.92     |
|    mse                  | 149      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.639    |
--------------------------------------

Training done.
training step :132, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:21,974 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:23,056 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.030 +/- 5.120
eval_results['h_violation']:[16 13  0  0 11  8 15  5  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]], eval_score:131.24446259544416
2023-09-05 11:53:23,061 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0874   |
|    entropy_loss         | 2.36     |
|    policy_loss          | 0.0096   |
|    value_loss           | 5.25     |
| stat/                   |          |
|    constraint_violation | 241      |
|    ep_constraint_vio... | 14.9     |
|    ep_length            | 139      |
|    ep_return            | 124      |
|    ep_reward            | 0.861    |
| stat_eval/              |          |
|    constraint_violation | 10.2     |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.907    |
|    mse                  | 140      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.604    |
--------------------------------------

Training done.
training step :133, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:26,449 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:27,536 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.222 +/- 3.712
eval_results['h_violation']:[ 0  0 16  0  0  0  0  1 10  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [ True]], eval_score:135.29894111482912
2023-09-05 11:53:27,541 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.031    |
|    entropy_loss         | 2.37     |
|    policy_loss          | 0.00873  |
|    value_loss           | 0.0363   |
| stat/                   |          |
|    constraint_violation | 180      |
|    ep_constraint_vio... | 10.9     |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.904    |
| stat_eval/              |          |
|    constraint_violation | 7.2      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.915    |
|    mse                  | 118      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.653    |
--------------------------------------

Training done.
training step :134, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:30,970 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:32,054 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.298 +/- 5.279
eval_results['h_violation']:[11  0  5  7  7  6 12  0  0  0], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]
 [ True]], eval_score:132.91414351181672
2023-09-05 11:53:32,059 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0192   |
|    entropy_loss         | 2.37     |
|    policy_loss          | 0.00786  |
|    value_loss           | 0.01     |
| stat/                   |          |
|    constraint_violation | 146      |
|    ep_constraint_vio... | 7.6      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.914    |
| stat_eval/              |          |
|    constraint_violation | 11       |
|    ep_length            | 150      |
|    ep_return            | 136      |
|    ep_reward            | 0.909    |
|    mse                  | 133      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.666    |
--------------------------------------

Training done.
training step :135, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:35,525 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:36,663 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.051 +/- 4.563
eval_results['h_violation']:[ 0  0  0  0  0  3  0  8  9 11], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]], eval_score:135.85185095538446
2023-09-05 11:53:36,667 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0928   |
|    entropy_loss         | 2.37     |
|    policy_loss          | 0.0231   |
|    value_loss           | 0.02     |
| stat/                   |          |
|    constraint_violation | 163      |
|    ep_constraint_vio... | 5.5      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
| stat_eval/              |          |
|    constraint_violation | 5.6      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.92     |
|    mse                  | 120      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.626    |
--------------------------------------

Training done.
training step :136, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:40,245 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:41,404 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.449 +/- 4.840
eval_results['h_violation']:[ 0  4  0  4 11 20  0  0  0  0], (eval_results['s_violation']>0):[[ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:136.68724404041805
2023-09-05 11:53:41,408 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0568   |
|    entropy_loss         | 2.37     |
|    policy_loss          | 0.0218   |
|    value_loss           | 0.0288   |
| stat/                   |          |
|    constraint_violation | 164      |
|    ep_constraint_vio... | 6.7      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
| stat_eval/              |          |
|    constraint_violation | 8.2      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.93     |
|    mse                  | 138      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.841    |
--------------------------------------

Training done.
training step :137, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:44,890 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:46,002 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 136.974 +/- 4.902
eval_results['h_violation']:[0 6 5 8 0 0 0 8 0 0], (eval_results['s_violation']>0):[[False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]
 [ True]], eval_score:135.05846818332404
2023-09-05 11:53:46,007 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0968   |
|    entropy_loss         | 2.37     |
|    policy_loss          | 0.0285   |
|    value_loss           | 0.0139   |
| stat/                   |          |
|    constraint_violation | 185      |
|    ep_constraint_vio... | 10.1     |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
| stat_eval/              |          |
|    constraint_violation | 10.2     |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.913    |
|    mse                  | 131      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.744    |
--------------------------------------

Training done.
training step :138, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:49,377 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:50,474 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.000 +/- 4.835
eval_results['h_violation']:[8 3 0 3 8 5 0 5 0 0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:136.72771638338764
2023-09-05 11:53:50,478 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0879   |
|    entropy_loss         | 2.38     |
|    policy_loss          | 0.0255   |
|    value_loss           | 0.133    |
| stat/                   |          |
|    constraint_violation | 185      |
|    ep_constraint_vio... | 10.8     |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.929    |
| stat_eval/              |          |
|    constraint_violation | 10.7     |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
|    mse                  | 137      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.646    |
--------------------------------------

Training done.
training step :139, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:53,945 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:55,030 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 139.858 +/- 2.849
eval_results['h_violation']:[ 6  0  0  0 15  0  6  0  2 13], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:136.8823289225161
2023-09-05 11:53:55,034 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.045    |
|    entropy_loss         | 2.37     |
|    policy_loss          | 0.0122   |
|    value_loss           | 0.0406   |
| stat/                   |          |
|    constraint_violation | 151      |
|    ep_constraint_vio... | 6.9      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.929    |
| stat_eval/              |          |
|    constraint_violation | 8.3      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.932    |
|    mse                  | 125      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.634    |
--------------------------------------

Training done.
training step :140, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:53:58,441 : Checkpoint | temp/model_latest.pt
2023-09-05 11:53:59,538 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.055 +/- 1.132
eval_results['h_violation']:[ 0 10 15  3  0  0  5  0  0  5], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [False]], eval_score:137.3704093612278
2023-09-05 11:53:59,542 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0623   |
|    entropy_loss         | 2.37     |
|    policy_loss          | 0.0309   |
|    value_loss           | 0.0252   |
| stat/                   |          |
|    constraint_violation | 234      |
|    ep_constraint_vio... | 11.7     |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.911    |
| stat_eval/              |          |
|    constraint_violation | 0.8      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.934    |
|    mse                  | 103      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.641    |
--------------------------------------

Training done.
training step :141, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:54:02,962 : Checkpoint | temp/model_latest.pt
2023-09-05 11:54:03,866 : Eval | ep_lengths 125.30 +/- 49.41 | ep_return 114.382 +/- 50.372
eval_results['h_violation']:[ 0  0  1  8  5  0 17  0  0 18], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:110.91732481251059
2023-09-05 11:54:03,870 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0697   |
|    entropy_loss         | 2.38     |
|    policy_loss          | 0.0414   |
|    value_loss           | 0.01     |
| stat/                   |          |
|    constraint_violation | 199      |
|    ep_constraint_vio... | 9.5      |
|    ep_length            | 150      |
|    ep_return            | 137      |
|    ep_reward            | 0.915    |
| stat_eval/              |          |
|    constraint_violation | 11.1     |
|    ep_length            | 125      |
|    ep_return            | 114      |
|    ep_reward            | 0.847    |
|    mse                  | 146      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.683    |
--------------------------------------

Training done.
training step :142, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:54:07,374 : Checkpoint | temp/model_latest.pt
2023-09-05 11:54:08,240 : Eval | ep_lengths 114.60 +/- 54.18 | ep_return 103.089 +/- 55.986
eval_results['h_violation']:[ 0  7  0 15  7 18 19 17  9  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:96.61706907730857
2023-09-05 11:54:08,245 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0342   |
|    entropy_loss         | 2.38     |
|    policy_loss          | 0.00829  |
|    value_loss           | 0.203    |
| stat/                   |          |
|    constraint_violation | 280      |
|    ep_constraint_vio... | 10.7     |
|    ep_length            | 125      |
|    ep_return            | 114      |
|    ep_reward            | 0.854    |
| stat_eval/              |          |
|    constraint_violation | 14.4     |
|    ep_length            | 115      |
|    ep_return            | 103      |
|    ep_reward            | 0.817    |
|    mse                  | 171      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.735    |
--------------------------------------

Training done.
training step :143, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:54:11,824 : Checkpoint | temp/model_latest.pt
2023-09-05 11:54:12,891 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.314 +/- 3.730
eval_results['h_violation']:[8 0 2 0 0 0 0 0 7 0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:137.08609938674078
2023-09-05 11:54:12,895 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0696   |
|    entropy_loss         | 2.39     |
|    policy_loss          | -0.00745 |
|    value_loss           | 20.1     |
| stat/                   |          |
|    constraint_violation | 163      |
|    ep_constraint_vio... | 5.8      |
|    ep_length            | 138      |
|    ep_return            | 128      |
|    ep_reward            | 0.902    |
| stat_eval/              |          |
|    constraint_violation | 13.2     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.922    |
|    mse                  | 140      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.634    |
--------------------------------------

Training done.
training step :144, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:54:16,107 : Checkpoint | temp/model_latest.pt
2023-09-05 11:54:17,199 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 140.007 +/- 3.728
eval_results['h_violation']:[15 10 11  0 11  9  3  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:135.84222868146395
2023-09-05 11:54:17,203 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0284   |
|    entropy_loss         | 2.39     |
|    policy_loss          | 0.000474 |
|    value_loss           | 0.845    |
| stat/                   |          |
|    constraint_violation | 145      |
|    ep_constraint_vio... | 8.2      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.928    |
| stat_eval/              |          |
|    constraint_violation | 7.9      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.933    |
|    mse                  | 135      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.631    |
--------------------------------------

Training done.
training step :145, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:54:20,397 : Checkpoint | temp/model_latest.pt
2023-09-05 11:54:21,456 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.490 +/- 3.333
eval_results['h_violation']:[ 9 18 13  2  8  8  8  8  4  9], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:135.3683143092674
2023-09-05 11:54:21,460 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.21     |
|    entropy_loss         | 2.38     |
|    policy_loss          | 0.037    |
|    value_loss           | 0.281    |
| stat/                   |          |
|    constraint_violation | 185      |
|    ep_constraint_vio... | 9.4      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.929    |
| stat_eval/              |          |
|    constraint_violation | 8.7      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.943    |
|    mse                  | 147      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.599    |
--------------------------------------

Training done.
training step :146, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:54:24,634 : Checkpoint | temp/model_latest.pt
2023-09-05 11:54:25,702 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 138.380 +/- 4.853
eval_results['h_violation']:[10  9  0  0  0  0  0  0  0  0], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]
 [False]
 [ True]
 [ True]], eval_score:137.02067426678803
2023-09-05 11:54:25,706 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.056    |
|    entropy_loss         | 2.39     |
|    policy_loss          | 0.00343  |
|    value_loss           | 0.14     |
| stat/                   |          |
|    constraint_violation | 137      |
|    ep_constraint_vio... | 6.6      |
|    ep_length            | 150      |
|    ep_return            | 140      |
|    ep_reward            | 0.931    |
| stat_eval/              |          |
|    constraint_violation | 8.6      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.923    |
|    mse                  | 127      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.607    |
--------------------------------------

Training done.
training step :147, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:54:28,903 : Checkpoint | temp/model_latest.pt
2023-09-05 11:54:29,967 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 141.249 +/- 3.221
eval_results['h_violation']:[ 0  0  5  0  0 16  0  0  6  0], (eval_results['s_violation']>0):[[False]
 [False]
 [False]
 [ True]
 [ True]
 [ True]
 [False]
 [False]
 [ True]
 [ True]], eval_score:139.34155208005757
2023-09-05 11:54:29,971 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0459   |
|    entropy_loss         | 2.39     |
|    policy_loss          | -0.00522 |
|    value_loss           | 0.0823   |
| stat/                   |          |
|    constraint_violation | 78       |
|    ep_constraint_vio... | 7.3      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
| stat_eval/              |          |
|    constraint_violation | 3.4      |
|    ep_length            | 150      |
|    ep_return            | 141      |
|    ep_reward            | 0.942    |
|    mse                  | 121      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.604    |
--------------------------------------

Training done.
training step :148, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:54:33,244 : Checkpoint | temp/model_latest.pt
2023-09-05 11:54:34,311 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.581 +/- 4.629
eval_results['h_violation']:[15  0 18 18 15  0 10  8  5  6], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]], eval_score:130.89921031051114
2023-09-05 11:54:34,314 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.038    |
|    entropy_loss         | 2.39     |
|    policy_loss          | 0.00188  |
|    value_loss           | 0.164    |
| stat/                   |          |
|    constraint_violation | 224      |
|    ep_constraint_vio... | 11.6     |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.918    |
| stat_eval/              |          |
|    constraint_violation | 10       |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.917    |
|    mse                  | 137      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.622    |
--------------------------------------

Training done.
training step :149, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
2023-09-05 11:54:37,509 : Checkpoint | temp/model_latest.pt
2023-09-05 11:54:38,577 : Eval | ep_lengths 150.00 +/- 0.00 | ep_return 137.531 +/- 5.454
eval_results['h_violation']:[ 0  0  0 11  0 13  0  0  7 10], (eval_results['s_violation']>0):[[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [False]], eval_score:134.63275815381184
2023-09-05 11:54:38,581 :
--------------------------------------
| lambda/                 |          |
|    current env steps    | 3e+03    |
|    current updating ... | 1        |
|    hard_lambda          | 0.699    |
|    lambda training step | 8        |
|    policy update step   | 5        |
|    soft_lambda          | 0.0391   |
|    trajectory scale     | 0        |
| loss/                   |          |
|    approx_kl            | 0.0392   |
|    entropy_loss         | 2.4      |
|    policy_loss          | -0.00807 |
|    value_loss           | 0.0311   |
| stat/                   |          |
|    constraint_violation | 113      |
|    ep_constraint_vio... | 7.5      |
|    ep_length            | 150      |
|    ep_return            | 139      |
|    ep_reward            | 0.927    |
| stat_eval/              |          |
|    constraint_violation | 7.9      |
|    ep_length            | 150      |
|    ep_return            | 138      |
|    ep_reward            | 0.917    |
|    mse                  | 124      |
| time/                   |          |
|    progress             | 1        |
|    step                 | 3e+03    |
|    step_time            | 0.605    |
--------------------------------------

Training done.
training step :150, total: 150.
||||||||||||||||||||||||||||||||||||||DEVICE USED:cpu, cpu|||||||||||||||||||||||||||||||||||||||||||
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 139.955
←[33maverage_rmse←[0m: 0.857
←[33mrmse←[0m: 0.857
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.857
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
----------------------------Large Circle Task-----------------------
number of hard violations
0
hard violation steps
[]
number of soft violations
14
soft violation steps
[  0   1   2   8   9  10  11  12  13  19  20  21  26 109]
scales used for training
[]
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 148.588
←[33maverage_rmse←[0m: 0.531
←[33mrmse←[0m: 0.531
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.531
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
----------------------------Small Circle Task-----------------------
number of hard violations
0
hard violation steps
[]
number of soft violations
2
soft violation steps
[0 1]
scales used for training
[]
←[33maverage_length←[0m: 150.000
←[33mlength←[0m: 150.000
←[33maverage_return←[0m: 115.250
←[33maverage_rmse←[0m: 0.763
←[33mrmse←[0m: 0.763
←[33mrmse_std←[0m: 0.000
←[33mworst_case_rmse_at_0.5←[0m: 0.763
←[33mfailure_rate←[0m: 0.000
←[33maverage_constraint_violation←[0m: 0.000
←[33mconstraint_violation_std←[0m: 0.000
←[33mconstraint_violation←[0m: 0.000
Evaluation done.
----------------------------Random Task-----------------------
number of hard violations
22
hard violation steps
[32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53]
number of soft violations
1
soft violation steps
[0]
scales used for training
[]
----------------------------Results and Parameters-------------------------
final value loss: 0.031093525793671185 | final policy loss: -0.008074308613329442
